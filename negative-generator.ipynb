{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd12e830",
   "metadata": {},
   "source": [
    "# Negative Tone Data Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6d930",
   "metadata": {},
   "source": [
    "This notebook contains code for an MLP neural network that generates negatively toned data based on the dataset. Feature vectors are then made from the negatively toned data and generated data then saved into .csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775f0cda",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eccd3655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from nltk import regexp_tokenize, WordNetLemmatizer\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2f00057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50c2279",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c222980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with pale blue berries. in these peaceful shad...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it flows so long as falls the rain</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and that is why, the lonesome day</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when i peruse the conquered fame of heroes, an...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of inward strife for truth and liberty.</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>to his ears there came a murmur of far seas be...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>the one good man in the world who knows me, --</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>faint voices lifted shrill with pain</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>an', fust you knowed on, back come charles the...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>in the wild glens rough shepherds will deplore</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>892 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text  Sentiment\n",
       "0    with pale blue berries. in these peaceful shad...        1.0\n",
       "1                   it flows so long as falls the rain        0.0\n",
       "2                    and that is why, the lonesome day       -1.0\n",
       "3    when i peruse the conquered fame of heroes, an...        2.0\n",
       "4              of inward strife for truth and liberty.        2.0\n",
       "..                                                 ...        ...\n",
       "887  to his ears there came a murmur of far seas be...        0.0\n",
       "888     the one good man in the world who knows me, --        1.0\n",
       "889               faint voices lifted shrill with pain       -1.0\n",
       "890  an', fust you knowed on, back come charles the...        0.0\n",
       "891     in the wild glens rough shepherds will deplore       -1.0\n",
       "\n",
       "[892 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv('poem_sentiment.csv', header=None, index_col=0, names=['Text', 'Sentiment'])\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a556975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and that is why, the lonesome day</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and so on. then a worthless gaud or two</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sounded o'er earth and sea its blast of war</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>want and woe, which torture us</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>an echo returned on the cold gray morn</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>in town, an' not the leanest runt</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>by death's frequented ways</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>rejection of his humanness</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>faint voices lifted shrill with pain</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>in the wild glens rough shepherds will deplore</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Text  Sentiment\n",
       "2                 and that is why, the lonesome day       -1.0\n",
       "8           and so on. then a worthless gaud or two       -1.0\n",
       "17      sounded o'er earth and sea its blast of war       -1.0\n",
       "37                   want and woe, which torture us       -1.0\n",
       "39           an echo returned on the cold gray morn       -1.0\n",
       "..                                              ...        ...\n",
       "874               in town, an' not the leanest runt       -1.0\n",
       "883                      by death's frequented ways       -1.0\n",
       "885                      rejection of his humanness       -1.0\n",
       "889            faint voices lifted shrill with pain       -1.0\n",
       "891  in the wild glens rough shepherds will deplore       -1.0\n",
       "\n",
       "[155 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative = df_raw[df_raw['Sentiment'] < 0]\n",
    "negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8ca11d",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45cd3956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"                 and that is why, the lonesome day\\n           and so on. then a worthless gaud or two\\n       sounded o'er earth and sea its blast of war\\n                    want and woe, which torture us\\n            an echo returned on the cold gray morn\\n       while i, ... i built up follies like a wall\\n          ah, what a pang of aching sharp surprise\\n                 and the old swallow-haunted barns\\n     the which she bearing home it burned her nest\\n    the crown of sorrow on their heads, their loss\\n               i lay and watched the lonely gloom;\\n          a sceptremonstrous, winged, intolerable.\\n while the rude winds blow off each shadowy crown.\\n         but o, nevermore can we prison him tight.\\n                 may meditate a whole youth's loss\\n        when thee, the eyes of that harsh long ago\\n        the foes inclosing, and his friend pursued\\nand bow to dread inquisitor and worship lords o...\\n        miles off, three dangerous miles, is home;\\n      else, sufferd, it will se\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text = negative['Text'].to_string(index=False)\n",
    "raw_text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e46bd8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"                 and that is why, the lonesome day\\n           and so on. then a worthless gaud or two\\n       sounded o'er earth and sea its blast of war\\n                    want and woe, which torture us\\n            an echo returned on the cold gray morn\\n       while i, ... i built up follies like a wall\\n          ah, what a pang of aching sharp surprise\\n                 and the old swallow-haunted barns\\n     the which she bearing home it burned her nest\\n    the crown of sorrow on their heads, their loss\\n               i lay and watched the lonely gloom;\\n          a sceptremonstrous, winged, intolerable.\\n while the rude winds blow off each shadowy crown.\\n         but o, nevermore can we prison him tight.\\n                 may meditate a whole youth's loss\\n        when thee, the eyes of that harsh long ago\\n        the foes inclosing, and his friend pursued\\nand bow to dread inquisitor and worship lords o...\\n        miles off, three dangerous miles, is home;\\n      else, sufferd, it will se\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all non-ASCII characters\n",
    "processed_text = re.sub(r'[^\\x00-\\x7f]', r'', raw_text).lower()\n",
    "processed_text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cd9097",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "987aadca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of word tokens: 1266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['and', 'that', 'is', 'why', 'the', 'lonesome', 'day', '\\n', 'and', 'so']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get word tokens from text\n",
    "word_tokens = regexp_tokenize(processed_text, pattern=r'[^\\S\\r\\n]+|[\\.,:;!?()--_\"]', gaps=True)\n",
    "word_tokens = [val for values in map(re.compile('[^\\t\\n]+|[\\t\\n]').findall, word_tokens) for val in values]\n",
    "print(f\"Number of word tokens: {len(word_tokens)}\")\n",
    "word_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f47cb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization done to make uncommon words more likely to be recognized by \n",
    "# Word2Vec model later when converting to feature vectors\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "word_tokens = [lemmatizer.lemmatize(token) for token in word_tokens] # Lemmatize nouns\n",
    "word_tokens = [lemmatizer.lemmatize(token, 'v') for token in word_tokens] # Lemmatize verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19ff426c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique word tokens: 576\n"
     ]
    }
   ],
   "source": [
    "# Get unique word tokens from word tokens\n",
    "unique_words = sorted(list(set(word_tokens)))\n",
    "print(f\"Number of unique word tokens: {len(unique_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86037479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " \"'\",\n",
       " \"'twas\",\n",
       " 'a',\n",
       " 'accomplish',\n",
       " 'ache',\n",
       " 'add',\n",
       " 'adulterate',\n",
       " 'afar',\n",
       " 'after']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create vocabulary of word tokens\n",
    "word_vocabulary = unique_words\n",
    "word_vocabulary[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842cf74d",
   "metadata": {},
   "source": [
    "### Create word-index mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d81c158c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '\\n',\n",
       " 1: \"'\",\n",
       " 2: \"'twas\",\n",
       " 3: 'a',\n",
       " 4: 'accomplish',\n",
       " 5: 'ache',\n",
       " 6: 'add',\n",
       " 7: 'adulterate',\n",
       " 8: 'afar',\n",
       " 9: 'after',\n",
       " 10: 'age',\n",
       " 11: 'ago',\n",
       " 12: 'ah',\n",
       " 13: 'air',\n",
       " 14: 'all',\n",
       " 15: 'altar',\n",
       " 16: 'always',\n",
       " 17: 'among',\n",
       " 18: 'an',\n",
       " 19: \"an'\",\n",
       " 20: 'and',\n",
       " 21: 'angel',\n",
       " 22: 'answer',\n",
       " 23: 'anxious',\n",
       " 24: 'around',\n",
       " 25: 'arrow',\n",
       " 26: 'ash',\n",
       " 27: 'ask',\n",
       " 28: 'at',\n",
       " 29: 'augur',\n",
       " 30: 'avenge',\n",
       " 31: 'away',\n",
       " 32: 'b',\n",
       " 33: 'bad',\n",
       " 34: 'barn',\n",
       " 35: 'barrenly',\n",
       " 36: 'bat',\n",
       " 37: 'be',\n",
       " 38: 'beam',\n",
       " 39: 'bear',\n",
       " 40: 'beat',\n",
       " 41: 'because',\n",
       " 42: 'become',\n",
       " 43: 'bed',\n",
       " 44: 'beguile',\n",
       " 45: 'behold',\n",
       " 46: 'bind',\n",
       " 47: 'bitter',\n",
       " 48: 'black',\n",
       " 49: 'blankness',\n",
       " 50: 'blast',\n",
       " 51: 'bleed',\n",
       " 52: 'blend',\n",
       " 53: 'blight',\n",
       " 54: 'blind',\n",
       " 55: 'blindness',\n",
       " 56: 'blood',\n",
       " 57: 'blow',\n",
       " 58: 'body',\n",
       " 59: 'bow',\n",
       " 60: 'brand',\n",
       " 61: 'break',\n",
       " 62: 'breast',\n",
       " 63: 'briareus',\n",
       " 64: 'build',\n",
       " 65: 'burn',\n",
       " 66: 'but',\n",
       " 67: 'by',\n",
       " 68: 'calumny',\n",
       " 69: 'can',\n",
       " 70: \"captive's\",\n",
       " 71: 'change',\n",
       " 72: 'child',\n",
       " 73: 'claim',\n",
       " 74: 'clatter',\n",
       " 75: 'cloud',\n",
       " 76: 'cloudy',\n",
       " 77: 'co',\n",
       " 78: 'cobweb',\n",
       " 79: 'cold',\n",
       " 80: 'come',\n",
       " 81: 'corps',\n",
       " 82: 'cou',\n",
       " 83: 'cough',\n",
       " 84: 'could',\n",
       " 85: 'course',\n",
       " 86: 'cripple',\n",
       " 87: 'cross',\n",
       " 88: 'crown',\n",
       " 89: 'cruell',\n",
       " 90: 'crush',\n",
       " 91: 'cry',\n",
       " 92: 'curse',\n",
       " 93: 'daily',\n",
       " 94: 'damn',\n",
       " 95: 'danger',\n",
       " 96: 'dangerous',\n",
       " 97: 'dare',\n",
       " 98: 'dark',\n",
       " 99: 'darkness',\n",
       " 100: 'dawn',\n",
       " 101: 'day',\n",
       " 102: 'dead',\n",
       " 103: 'deadly',\n",
       " 104: 'deaf',\n",
       " 105: 'death',\n",
       " 106: \"death's\",\n",
       " 107: 'delusive',\n",
       " 108: 'deplore',\n",
       " 109: 'despair',\n",
       " 110: 'didst',\n",
       " 111: 'dip',\n",
       " 112: 'discontent',\n",
       " 113: 'distress',\n",
       " 114: 'disunion',\n",
       " 115: 'do',\n",
       " 116: 'down',\n",
       " 117: 'dread',\n",
       " 118: 'dreadful',\n",
       " 119: 'drear',\n",
       " 120: \"drill's\",\n",
       " 121: 'droop',\n",
       " 122: 'dull',\n",
       " 123: 'dumb',\n",
       " 124: 'dwell',\n",
       " 125: \"e'en\",\n",
       " 126: 'each',\n",
       " 127: 'earth',\n",
       " 128: 'echo',\n",
       " 129: 'else',\n",
       " 130: 'end',\n",
       " 131: 'enemy',\n",
       " 132: 'enough',\n",
       " 133: 'envy',\n",
       " 134: 'etch',\n",
       " 135: 'expire',\n",
       " 136: 'eye',\n",
       " 137: 'face',\n",
       " 138: 'faint',\n",
       " 139: 'fall',\n",
       " 140: 'false',\n",
       " 141: 'fatal',\n",
       " 142: 'fear',\n",
       " 143: 'featureless',\n",
       " 144: \"feel'st\",\n",
       " 145: 'fell',\n",
       " 146: 'fer',\n",
       " 147: 'fetter',\n",
       " 148: 'fiery',\n",
       " 149: 'fight',\n",
       " 150: 'fill',\n",
       " 151: 'fire',\n",
       " 152: 'flame',\n",
       " 153: 'flicker',\n",
       " 154: 'flight',\n",
       " 155: 'flood',\n",
       " 156: 'flower',\n",
       " 157: 'foe',\n",
       " 158: 'foeman',\n",
       " 159: 'foggy',\n",
       " 160: 'folly',\n",
       " 161: 'food',\n",
       " 162: 'fool',\n",
       " 163: 'for',\n",
       " 164: 'forcd',\n",
       " 165: 'force',\n",
       " 166: 'foredoom',\n",
       " 167: 'forelaid',\n",
       " 168: 'forever',\n",
       " 169: 'forget',\n",
       " 170: 'forlorn',\n",
       " 171: 'fountain',\n",
       " 172: 'fraud',\n",
       " 173: 'fray',\n",
       " 174: 'frequent',\n",
       " 175: 'friend',\n",
       " 176: 'from',\n",
       " 177: 'frown',\n",
       " 178: 'fury',\n",
       " 179: 'future',\n",
       " 180: 'gallic',\n",
       " 181: 'gaud',\n",
       " 182: 'generation',\n",
       " 183: 'get',\n",
       " 184: 'girl',\n",
       " 185: 'give',\n",
       " 186: 'glance',\n",
       " 187: 'glen',\n",
       " 188: 'gloom',\n",
       " 189: 'goad',\n",
       " 190: 'god',\n",
       " 191: \"god's\",\n",
       " 192: 'gray',\n",
       " 193: 'great',\n",
       " 194: 'groom',\n",
       " 195: 'guard',\n",
       " 196: 'guile',\n",
       " 197: 'gun',\n",
       " 198: 'ha',\n",
       " 199: 'half',\n",
       " 200: 'hand',\n",
       " 201: 'hang',\n",
       " 202: 'harsh',\n",
       " 203: 'hast',\n",
       " 204: 'hate',\n",
       " 205: 'haunt',\n",
       " 206: 'have',\n",
       " 207: 'he',\n",
       " 208: 'head',\n",
       " 209: 'heap',\n",
       " 210: 'heart',\n",
       " 211: 'hearthstone',\n",
       " 212: 'heavy',\n",
       " 213: 'hee',\n",
       " 214: 'hell',\n",
       " 215: 'her',\n",
       " 216: 'here',\n",
       " 217: 'hi',\n",
       " 218: 'high',\n",
       " 219: 'him',\n",
       " 220: 'his',\n",
       " 221: 'hither',\n",
       " 222: 'home',\n",
       " 223: 'homesick',\n",
       " 224: 'hope',\n",
       " 225: 'house',\n",
       " 226: 'how',\n",
       " 227: 'howl',\n",
       " 228: 'human',\n",
       " 229: 'humanness',\n",
       " 230: 'i',\n",
       " 231: \"i've\",\n",
       " 232: 'if',\n",
       " 233: 'ignorant',\n",
       " 234: 'ill',\n",
       " 235: 'in',\n",
       " 236: 'inand',\n",
       " 237: 'inclose',\n",
       " 238: 'inexorable',\n",
       " 239: 'infernal',\n",
       " 240: 'inquisitor',\n",
       " 241: 'into',\n",
       " 242: 'intolerable',\n",
       " 243: 'it',\n",
       " 244: 'jane',\n",
       " 245: 'kneel',\n",
       " 246: 'know',\n",
       " 247: 'labyrinth',\n",
       " 248: 'land',\n",
       " 249: 'lap',\n",
       " 250: 'lave',\n",
       " 251: 'law',\n",
       " 252: 'lay',\n",
       " 253: 'le',\n",
       " 254: 'leaf',\n",
       " 255: 'leanest',\n",
       " 256: 'leave',\n",
       " 257: 'let',\n",
       " 258: 'lie',\n",
       " 259: 'life',\n",
       " 260: 'lift',\n",
       " 261: 'like',\n",
       " 262: 'line',\n",
       " 263: 'live',\n",
       " 264: 'liveliest',\n",
       " 265: 'load',\n",
       " 266: 'lone',\n",
       " 267: 'lonely',\n",
       " 268: 'lonesome',\n",
       " 269: 'long',\n",
       " 270: 'look',\n",
       " 271: 'lord',\n",
       " 272: 'lose',\n",
       " 273: 'loss',\n",
       " 274: 'lowly',\n",
       " 275: 'lucrece',\n",
       " 276: 'mad',\n",
       " 277: 'madness',\n",
       " 278: 'maidenhead',\n",
       " 279: 'make',\n",
       " 280: 'mankind',\n",
       " 281: 'may',\n",
       " 282: 'me',\n",
       " 283: 'meditate',\n",
       " 284: 'melancholy',\n",
       " 285: 'melt',\n",
       " 286: 'men',\n",
       " 287: 'might',\n",
       " 288: 'mile',\n",
       " 289: 'mine',\n",
       " 290: 'mission',\n",
       " 291: 'moan',\n",
       " 292: 'mole',\n",
       " 293: 'moloch',\n",
       " 294: 'moment',\n",
       " 295: 'monkey',\n",
       " 296: 'monster',\n",
       " 297: 'monstrous',\n",
       " 298: 'mood',\n",
       " 299: 'moon',\n",
       " 300: 'more',\n",
       " 301: 'morn',\n",
       " 302: 'most',\n",
       " 303: 'mourn',\n",
       " 304: 'mournfully',\n",
       " 305: \"mov'd\",\n",
       " 306: 'multiply',\n",
       " 307: 'murmur',\n",
       " 308: 'must',\n",
       " 309: 'my',\n",
       " 310: \"n't\",\n",
       " 311: 'nail',\n",
       " 312: 'name',\n",
       " 313: \"ne'er\",\n",
       " 314: 'nearest',\n",
       " 315: 'nerve',\n",
       " 316: 'nest',\n",
       " 317: 'never',\n",
       " 318: 'nevermore',\n",
       " 319: 'nice',\n",
       " 320: 'night',\n",
       " 321: 'no',\n",
       " 322: 'none',\n",
       " 323: 'not',\n",
       " 324: 'nothing',\n",
       " 325: 'now',\n",
       " 326: 'nymph',\n",
       " 327: 'o',\n",
       " 328: \"o'er\",\n",
       " 329: 'obliterate',\n",
       " 330: \"oblivion's\",\n",
       " 331: 'of',\n",
       " 332: 'off',\n",
       " 333: 'offspring',\n",
       " 334: 'old',\n",
       " 335: 'on',\n",
       " 336: 'once',\n",
       " 337: 'one',\n",
       " 338: 'open',\n",
       " 339: 'or',\n",
       " 340: 'our',\n",
       " 341: 'out',\n",
       " 342: 'pain',\n",
       " 343: 'pallid',\n",
       " 344: 'pang',\n",
       " 345: 'pass',\n",
       " 346: 'pathetic',\n",
       " 347: 'people',\n",
       " 348: 'perish',\n",
       " 349: 'phrase',\n",
       " 350: 'pillar',\n",
       " 351: 'pity',\n",
       " 352: 'poor',\n",
       " 353: 'portend',\n",
       " 354: 'pride',\n",
       " 355: 'priest',\n",
       " 356: 'prison',\n",
       " 357: 'promise',\n",
       " 358: 'pu',\n",
       " 359: 'pursue',\n",
       " 360: 'quicken',\n",
       " 361: 'quit',\n",
       " 362: 'quiver',\n",
       " 363: 'rage',\n",
       " 364: 'range',\n",
       " 365: 'rave',\n",
       " 366: 'receave',\n",
       " 367: 'regin',\n",
       " 368: 'rejection',\n",
       " 369: 'rest',\n",
       " 370: 'return',\n",
       " 371: 'ridiculous',\n",
       " 372: 'right',\n",
       " 373: 'ripe',\n",
       " 374: 'rise',\n",
       " 375: 'rocky',\n",
       " 376: 'roll',\n",
       " 377: 'root',\n",
       " 378: 'rough',\n",
       " 379: 'rude',\n",
       " 380: 'ruin',\n",
       " 381: 'run',\n",
       " 382: 'runt',\n",
       " 383: 'sad',\n",
       " 384: 'satrap',\n",
       " 385: 'savage',\n",
       " 386: 'save',\n",
       " 387: 'say',\n",
       " 388: 'scare',\n",
       " 389: 'scarlet',\n",
       " 390: 'scatter',\n",
       " 391: 'sceptremonstrous',\n",
       " 392: 'scorn',\n",
       " 393: 'sea',\n",
       " 394: 'seditious',\n",
       " 395: 'see',\n",
       " 396: 'seek',\n",
       " 397: 'seem',\n",
       " 398: 'selfishness',\n",
       " 399: 'send',\n",
       " 400: 'serious',\n",
       " 401: 'set',\n",
       " 402: \"sha'\",\n",
       " 403: 'shadow',\n",
       " 404: 'shadowy',\n",
       " 405: 'shall',\n",
       " 406: 'sharp',\n",
       " 407: 'she',\n",
       " 408: 'shepherd',\n",
       " 409: 'shiver',\n",
       " 410: 'shore',\n",
       " 411: 'shout',\n",
       " 412: 'shrill',\n",
       " 413: 'shun',\n",
       " 414: 'silk',\n",
       " 415: 'silly',\n",
       " 416: 'sit',\n",
       " 417: 'sitteth',\n",
       " 418: 'slaughter',\n",
       " 419: 'slave',\n",
       " 420: 'slavery',\n",
       " 421: 'slay',\n",
       " 422: 'sleep',\n",
       " 423: 'slumber',\n",
       " 424: 'smile',\n",
       " 425: 'smother',\n",
       " 426: 'smoulder',\n",
       " 427: 'so',\n",
       " 428: 'soft',\n",
       " 429: 'solemn',\n",
       " 430: 'some',\n",
       " 431: 'sophist',\n",
       " 432: 'sorrow',\n",
       " 433: \"sorrow's\",\n",
       " 434: 'sorrowful',\n",
       " 435: 'sound',\n",
       " 436: 'spake',\n",
       " 437: 'spoil',\n",
       " 438: 'spy',\n",
       " 439: 'star',\n",
       " 440: 'steal',\n",
       " 441: 'steerd',\n",
       " 442: 'stiff',\n",
       " 443: 'stifle',\n",
       " 444: 'still',\n",
       " 445: 'stock',\n",
       " 446: 'stone',\n",
       " 447: 'stormy',\n",
       " 448: 'strange',\n",
       " 449: 'strangle',\n",
       " 450: 'street',\n",
       " 451: 'string',\n",
       " 452: 'strive',\n",
       " 453: 'struggle',\n",
       " 454: 'such',\n",
       " 455: 'sufferd',\n",
       " 456: 'suicide',\n",
       " 457: 'summon',\n",
       " 458: 'sun',\n",
       " 459: 'surprise',\n",
       " 460: 'swallow',\n",
       " 461: 'sweep',\n",
       " 462: 'sword',\n",
       " 463: 'take',\n",
       " 464: 'task',\n",
       " 465: 'teach',\n",
       " 466: 'tear',\n",
       " 467: 'tempest',\n",
       " 468: 'th',\n",
       " 469: 'than',\n",
       " 470: 'that',\n",
       " 471: 'the',\n",
       " 472: 'thee',\n",
       " 473: 'their',\n",
       " 474: 'them',\n",
       " 475: 'then',\n",
       " 476: 'there',\n",
       " 477: 'these',\n",
       " 478: 'they',\n",
       " 479: 'thine',\n",
       " 480: 'thing',\n",
       " 481: 'think',\n",
       " 482: 'this',\n",
       " 483: 'those',\n",
       " 484: 'thou',\n",
       " 485: 'though',\n",
       " 486: 'thousand',\n",
       " 487: 'threaten',\n",
       " 488: 'three',\n",
       " 489: 'thro',\n",
       " 490: 'throb',\n",
       " 491: 'through',\n",
       " 492: 'throughout',\n",
       " 493: 'throw',\n",
       " 494: 'thunder',\n",
       " 495: 'thus',\n",
       " 496: 'thy',\n",
       " 497: 'tide',\n",
       " 498: 'tight',\n",
       " 499: 'till',\n",
       " 500: 'time',\n",
       " 501: \"time's\",\n",
       " 502: 'tinkle',\n",
       " 503: 'tire',\n",
       " 504: 'to',\n",
       " 505: 'torment',\n",
       " 506: 'torture',\n",
       " 507: 'town',\n",
       " 508: 'trail',\n",
       " 509: 'treatin',\n",
       " 510: 'trouble',\n",
       " 511: 'tumble',\n",
       " 512: 'twas',\n",
       " 513: 'twilight',\n",
       " 514: 'two',\n",
       " 515: 'u',\n",
       " 516: 'unloved',\n",
       " 517: 'until',\n",
       " 518: 'up',\n",
       " 519: 'utter',\n",
       " 520: 'vain',\n",
       " 521: 'vapour',\n",
       " 522: 'vehement',\n",
       " 523: 'visual',\n",
       " 524: 'voice',\n",
       " 525: 'wa',\n",
       " 526: 'wake',\n",
       " 527: 'wall',\n",
       " 528: 'wander',\n",
       " 529: 'want',\n",
       " 530: 'war',\n",
       " 531: 'warlike',\n",
       " 532: 'warn',\n",
       " 533: 'waste',\n",
       " 534: 'watch',\n",
       " 535: 'water',\n",
       " 536: 'waver',\n",
       " 537: 'way',\n",
       " 538: 'we',\n",
       " 539: 'weak',\n",
       " 540: 'weight',\n",
       " 541: 'weird',\n",
       " 542: 'what',\n",
       " 543: 'wheeze',\n",
       " 544: 'when',\n",
       " 545: 'where',\n",
       " 546: 'which',\n",
       " 547: 'while',\n",
       " 548: 'who',\n",
       " 549: 'whole',\n",
       " 550: 'why',\n",
       " 551: 'wild',\n",
       " 552: 'will',\n",
       " 553: 'wilt',\n",
       " 554: 'wind',\n",
       " 555: 'wing',\n",
       " 556: 'winter',\n",
       " 557: 'with',\n",
       " 558: 'wither',\n",
       " 559: 'within',\n",
       " 560: 'woe',\n",
       " 561: 'woman',\n",
       " 562: 'word',\n",
       " 563: 'world',\n",
       " 564: 'worship',\n",
       " 565: 'worthless',\n",
       " 566: 'would',\n",
       " 567: 'wrack',\n",
       " 568: 'wreck',\n",
       " 569: 'wrinkle',\n",
       " 570: 'writ',\n",
       " 571: 'wrong',\n",
       " 572: \"yo'\",\n",
       " 573: 'you',\n",
       " 574: 'your',\n",
       " 575: \"youth's\"}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create index-word mappings \n",
    "indices_words = dict((index, word) for index, word in enumerate(unique_words))\n",
    "indices_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e485f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " \"'\": 1,\n",
       " \"'twas\": 2,\n",
       " 'a': 3,\n",
       " 'accomplish': 4,\n",
       " 'ache': 5,\n",
       " 'add': 6,\n",
       " 'adulterate': 7,\n",
       " 'afar': 8,\n",
       " 'after': 9,\n",
       " 'age': 10,\n",
       " 'ago': 11,\n",
       " 'ah': 12,\n",
       " 'air': 13,\n",
       " 'all': 14,\n",
       " 'altar': 15,\n",
       " 'always': 16,\n",
       " 'among': 17,\n",
       " 'an': 18,\n",
       " \"an'\": 19,\n",
       " 'and': 20,\n",
       " 'angel': 21,\n",
       " 'answer': 22,\n",
       " 'anxious': 23,\n",
       " 'around': 24,\n",
       " 'arrow': 25,\n",
       " 'ash': 26,\n",
       " 'ask': 27,\n",
       " 'at': 28,\n",
       " 'augur': 29,\n",
       " 'avenge': 30,\n",
       " 'away': 31,\n",
       " 'b': 32,\n",
       " 'bad': 33,\n",
       " 'barn': 34,\n",
       " 'barrenly': 35,\n",
       " 'bat': 36,\n",
       " 'be': 37,\n",
       " 'beam': 38,\n",
       " 'bear': 39,\n",
       " 'beat': 40,\n",
       " 'because': 41,\n",
       " 'become': 42,\n",
       " 'bed': 43,\n",
       " 'beguile': 44,\n",
       " 'behold': 45,\n",
       " 'bind': 46,\n",
       " 'bitter': 47,\n",
       " 'black': 48,\n",
       " 'blankness': 49,\n",
       " 'blast': 50,\n",
       " 'bleed': 51,\n",
       " 'blend': 52,\n",
       " 'blight': 53,\n",
       " 'blind': 54,\n",
       " 'blindness': 55,\n",
       " 'blood': 56,\n",
       " 'blow': 57,\n",
       " 'body': 58,\n",
       " 'bow': 59,\n",
       " 'brand': 60,\n",
       " 'break': 61,\n",
       " 'breast': 62,\n",
       " 'briareus': 63,\n",
       " 'build': 64,\n",
       " 'burn': 65,\n",
       " 'but': 66,\n",
       " 'by': 67,\n",
       " 'calumny': 68,\n",
       " 'can': 69,\n",
       " \"captive's\": 70,\n",
       " 'change': 71,\n",
       " 'child': 72,\n",
       " 'claim': 73,\n",
       " 'clatter': 74,\n",
       " 'cloud': 75,\n",
       " 'cloudy': 76,\n",
       " 'co': 77,\n",
       " 'cobweb': 78,\n",
       " 'cold': 79,\n",
       " 'come': 80,\n",
       " 'corps': 81,\n",
       " 'cou': 82,\n",
       " 'cough': 83,\n",
       " 'could': 84,\n",
       " 'course': 85,\n",
       " 'cripple': 86,\n",
       " 'cross': 87,\n",
       " 'crown': 88,\n",
       " 'cruell': 89,\n",
       " 'crush': 90,\n",
       " 'cry': 91,\n",
       " 'curse': 92,\n",
       " 'daily': 93,\n",
       " 'damn': 94,\n",
       " 'danger': 95,\n",
       " 'dangerous': 96,\n",
       " 'dare': 97,\n",
       " 'dark': 98,\n",
       " 'darkness': 99,\n",
       " 'dawn': 100,\n",
       " 'day': 101,\n",
       " 'dead': 102,\n",
       " 'deadly': 103,\n",
       " 'deaf': 104,\n",
       " 'death': 105,\n",
       " \"death's\": 106,\n",
       " 'delusive': 107,\n",
       " 'deplore': 108,\n",
       " 'despair': 109,\n",
       " 'didst': 110,\n",
       " 'dip': 111,\n",
       " 'discontent': 112,\n",
       " 'distress': 113,\n",
       " 'disunion': 114,\n",
       " 'do': 115,\n",
       " 'down': 116,\n",
       " 'dread': 117,\n",
       " 'dreadful': 118,\n",
       " 'drear': 119,\n",
       " \"drill's\": 120,\n",
       " 'droop': 121,\n",
       " 'dull': 122,\n",
       " 'dumb': 123,\n",
       " 'dwell': 124,\n",
       " \"e'en\": 125,\n",
       " 'each': 126,\n",
       " 'earth': 127,\n",
       " 'echo': 128,\n",
       " 'else': 129,\n",
       " 'end': 130,\n",
       " 'enemy': 131,\n",
       " 'enough': 132,\n",
       " 'envy': 133,\n",
       " 'etch': 134,\n",
       " 'expire': 135,\n",
       " 'eye': 136,\n",
       " 'face': 137,\n",
       " 'faint': 138,\n",
       " 'fall': 139,\n",
       " 'false': 140,\n",
       " 'fatal': 141,\n",
       " 'fear': 142,\n",
       " 'featureless': 143,\n",
       " \"feel'st\": 144,\n",
       " 'fell': 145,\n",
       " 'fer': 146,\n",
       " 'fetter': 147,\n",
       " 'fiery': 148,\n",
       " 'fight': 149,\n",
       " 'fill': 150,\n",
       " 'fire': 151,\n",
       " 'flame': 152,\n",
       " 'flicker': 153,\n",
       " 'flight': 154,\n",
       " 'flood': 155,\n",
       " 'flower': 156,\n",
       " 'foe': 157,\n",
       " 'foeman': 158,\n",
       " 'foggy': 159,\n",
       " 'folly': 160,\n",
       " 'food': 161,\n",
       " 'fool': 162,\n",
       " 'for': 163,\n",
       " 'forcd': 164,\n",
       " 'force': 165,\n",
       " 'foredoom': 166,\n",
       " 'forelaid': 167,\n",
       " 'forever': 168,\n",
       " 'forget': 169,\n",
       " 'forlorn': 170,\n",
       " 'fountain': 171,\n",
       " 'fraud': 172,\n",
       " 'fray': 173,\n",
       " 'frequent': 174,\n",
       " 'friend': 175,\n",
       " 'from': 176,\n",
       " 'frown': 177,\n",
       " 'fury': 178,\n",
       " 'future': 179,\n",
       " 'gallic': 180,\n",
       " 'gaud': 181,\n",
       " 'generation': 182,\n",
       " 'get': 183,\n",
       " 'girl': 184,\n",
       " 'give': 185,\n",
       " 'glance': 186,\n",
       " 'glen': 187,\n",
       " 'gloom': 188,\n",
       " 'goad': 189,\n",
       " 'god': 190,\n",
       " \"god's\": 191,\n",
       " 'gray': 192,\n",
       " 'great': 193,\n",
       " 'groom': 194,\n",
       " 'guard': 195,\n",
       " 'guile': 196,\n",
       " 'gun': 197,\n",
       " 'ha': 198,\n",
       " 'half': 199,\n",
       " 'hand': 200,\n",
       " 'hang': 201,\n",
       " 'harsh': 202,\n",
       " 'hast': 203,\n",
       " 'hate': 204,\n",
       " 'haunt': 205,\n",
       " 'have': 206,\n",
       " 'he': 207,\n",
       " 'head': 208,\n",
       " 'heap': 209,\n",
       " 'heart': 210,\n",
       " 'hearthstone': 211,\n",
       " 'heavy': 212,\n",
       " 'hee': 213,\n",
       " 'hell': 214,\n",
       " 'her': 215,\n",
       " 'here': 216,\n",
       " 'hi': 217,\n",
       " 'high': 218,\n",
       " 'him': 219,\n",
       " 'his': 220,\n",
       " 'hither': 221,\n",
       " 'home': 222,\n",
       " 'homesick': 223,\n",
       " 'hope': 224,\n",
       " 'house': 225,\n",
       " 'how': 226,\n",
       " 'howl': 227,\n",
       " 'human': 228,\n",
       " 'humanness': 229,\n",
       " 'i': 230,\n",
       " \"i've\": 231,\n",
       " 'if': 232,\n",
       " 'ignorant': 233,\n",
       " 'ill': 234,\n",
       " 'in': 235,\n",
       " 'inand': 236,\n",
       " 'inclose': 237,\n",
       " 'inexorable': 238,\n",
       " 'infernal': 239,\n",
       " 'inquisitor': 240,\n",
       " 'into': 241,\n",
       " 'intolerable': 242,\n",
       " 'it': 243,\n",
       " 'jane': 244,\n",
       " 'kneel': 245,\n",
       " 'know': 246,\n",
       " 'labyrinth': 247,\n",
       " 'land': 248,\n",
       " 'lap': 249,\n",
       " 'lave': 250,\n",
       " 'law': 251,\n",
       " 'lay': 252,\n",
       " 'le': 253,\n",
       " 'leaf': 254,\n",
       " 'leanest': 255,\n",
       " 'leave': 256,\n",
       " 'let': 257,\n",
       " 'lie': 258,\n",
       " 'life': 259,\n",
       " 'lift': 260,\n",
       " 'like': 261,\n",
       " 'line': 262,\n",
       " 'live': 263,\n",
       " 'liveliest': 264,\n",
       " 'load': 265,\n",
       " 'lone': 266,\n",
       " 'lonely': 267,\n",
       " 'lonesome': 268,\n",
       " 'long': 269,\n",
       " 'look': 270,\n",
       " 'lord': 271,\n",
       " 'lose': 272,\n",
       " 'loss': 273,\n",
       " 'lowly': 274,\n",
       " 'lucrece': 275,\n",
       " 'mad': 276,\n",
       " 'madness': 277,\n",
       " 'maidenhead': 278,\n",
       " 'make': 279,\n",
       " 'mankind': 280,\n",
       " 'may': 281,\n",
       " 'me': 282,\n",
       " 'meditate': 283,\n",
       " 'melancholy': 284,\n",
       " 'melt': 285,\n",
       " 'men': 286,\n",
       " 'might': 287,\n",
       " 'mile': 288,\n",
       " 'mine': 289,\n",
       " 'mission': 290,\n",
       " 'moan': 291,\n",
       " 'mole': 292,\n",
       " 'moloch': 293,\n",
       " 'moment': 294,\n",
       " 'monkey': 295,\n",
       " 'monster': 296,\n",
       " 'monstrous': 297,\n",
       " 'mood': 298,\n",
       " 'moon': 299,\n",
       " 'more': 300,\n",
       " 'morn': 301,\n",
       " 'most': 302,\n",
       " 'mourn': 303,\n",
       " 'mournfully': 304,\n",
       " \"mov'd\": 305,\n",
       " 'multiply': 306,\n",
       " 'murmur': 307,\n",
       " 'must': 308,\n",
       " 'my': 309,\n",
       " \"n't\": 310,\n",
       " 'nail': 311,\n",
       " 'name': 312,\n",
       " \"ne'er\": 313,\n",
       " 'nearest': 314,\n",
       " 'nerve': 315,\n",
       " 'nest': 316,\n",
       " 'never': 317,\n",
       " 'nevermore': 318,\n",
       " 'nice': 319,\n",
       " 'night': 320,\n",
       " 'no': 321,\n",
       " 'none': 322,\n",
       " 'not': 323,\n",
       " 'nothing': 324,\n",
       " 'now': 325,\n",
       " 'nymph': 326,\n",
       " 'o': 327,\n",
       " \"o'er\": 328,\n",
       " 'obliterate': 329,\n",
       " \"oblivion's\": 330,\n",
       " 'of': 331,\n",
       " 'off': 332,\n",
       " 'offspring': 333,\n",
       " 'old': 334,\n",
       " 'on': 335,\n",
       " 'once': 336,\n",
       " 'one': 337,\n",
       " 'open': 338,\n",
       " 'or': 339,\n",
       " 'our': 340,\n",
       " 'out': 341,\n",
       " 'pain': 342,\n",
       " 'pallid': 343,\n",
       " 'pang': 344,\n",
       " 'pass': 345,\n",
       " 'pathetic': 346,\n",
       " 'people': 347,\n",
       " 'perish': 348,\n",
       " 'phrase': 349,\n",
       " 'pillar': 350,\n",
       " 'pity': 351,\n",
       " 'poor': 352,\n",
       " 'portend': 353,\n",
       " 'pride': 354,\n",
       " 'priest': 355,\n",
       " 'prison': 356,\n",
       " 'promise': 357,\n",
       " 'pu': 358,\n",
       " 'pursue': 359,\n",
       " 'quicken': 360,\n",
       " 'quit': 361,\n",
       " 'quiver': 362,\n",
       " 'rage': 363,\n",
       " 'range': 364,\n",
       " 'rave': 365,\n",
       " 'receave': 366,\n",
       " 'regin': 367,\n",
       " 'rejection': 368,\n",
       " 'rest': 369,\n",
       " 'return': 370,\n",
       " 'ridiculous': 371,\n",
       " 'right': 372,\n",
       " 'ripe': 373,\n",
       " 'rise': 374,\n",
       " 'rocky': 375,\n",
       " 'roll': 376,\n",
       " 'root': 377,\n",
       " 'rough': 378,\n",
       " 'rude': 379,\n",
       " 'ruin': 380,\n",
       " 'run': 381,\n",
       " 'runt': 382,\n",
       " 'sad': 383,\n",
       " 'satrap': 384,\n",
       " 'savage': 385,\n",
       " 'save': 386,\n",
       " 'say': 387,\n",
       " 'scare': 388,\n",
       " 'scarlet': 389,\n",
       " 'scatter': 390,\n",
       " 'sceptremonstrous': 391,\n",
       " 'scorn': 392,\n",
       " 'sea': 393,\n",
       " 'seditious': 394,\n",
       " 'see': 395,\n",
       " 'seek': 396,\n",
       " 'seem': 397,\n",
       " 'selfishness': 398,\n",
       " 'send': 399,\n",
       " 'serious': 400,\n",
       " 'set': 401,\n",
       " \"sha'\": 402,\n",
       " 'shadow': 403,\n",
       " 'shadowy': 404,\n",
       " 'shall': 405,\n",
       " 'sharp': 406,\n",
       " 'she': 407,\n",
       " 'shepherd': 408,\n",
       " 'shiver': 409,\n",
       " 'shore': 410,\n",
       " 'shout': 411,\n",
       " 'shrill': 412,\n",
       " 'shun': 413,\n",
       " 'silk': 414,\n",
       " 'silly': 415,\n",
       " 'sit': 416,\n",
       " 'sitteth': 417,\n",
       " 'slaughter': 418,\n",
       " 'slave': 419,\n",
       " 'slavery': 420,\n",
       " 'slay': 421,\n",
       " 'sleep': 422,\n",
       " 'slumber': 423,\n",
       " 'smile': 424,\n",
       " 'smother': 425,\n",
       " 'smoulder': 426,\n",
       " 'so': 427,\n",
       " 'soft': 428,\n",
       " 'solemn': 429,\n",
       " 'some': 430,\n",
       " 'sophist': 431,\n",
       " 'sorrow': 432,\n",
       " \"sorrow's\": 433,\n",
       " 'sorrowful': 434,\n",
       " 'sound': 435,\n",
       " 'spake': 436,\n",
       " 'spoil': 437,\n",
       " 'spy': 438,\n",
       " 'star': 439,\n",
       " 'steal': 440,\n",
       " 'steerd': 441,\n",
       " 'stiff': 442,\n",
       " 'stifle': 443,\n",
       " 'still': 444,\n",
       " 'stock': 445,\n",
       " 'stone': 446,\n",
       " 'stormy': 447,\n",
       " 'strange': 448,\n",
       " 'strangle': 449,\n",
       " 'street': 450,\n",
       " 'string': 451,\n",
       " 'strive': 452,\n",
       " 'struggle': 453,\n",
       " 'such': 454,\n",
       " 'sufferd': 455,\n",
       " 'suicide': 456,\n",
       " 'summon': 457,\n",
       " 'sun': 458,\n",
       " 'surprise': 459,\n",
       " 'swallow': 460,\n",
       " 'sweep': 461,\n",
       " 'sword': 462,\n",
       " 'take': 463,\n",
       " 'task': 464,\n",
       " 'teach': 465,\n",
       " 'tear': 466,\n",
       " 'tempest': 467,\n",
       " 'th': 468,\n",
       " 'than': 469,\n",
       " 'that': 470,\n",
       " 'the': 471,\n",
       " 'thee': 472,\n",
       " 'their': 473,\n",
       " 'them': 474,\n",
       " 'then': 475,\n",
       " 'there': 476,\n",
       " 'these': 477,\n",
       " 'they': 478,\n",
       " 'thine': 479,\n",
       " 'thing': 480,\n",
       " 'think': 481,\n",
       " 'this': 482,\n",
       " 'those': 483,\n",
       " 'thou': 484,\n",
       " 'though': 485,\n",
       " 'thousand': 486,\n",
       " 'threaten': 487,\n",
       " 'three': 488,\n",
       " 'thro': 489,\n",
       " 'throb': 490,\n",
       " 'through': 491,\n",
       " 'throughout': 492,\n",
       " 'throw': 493,\n",
       " 'thunder': 494,\n",
       " 'thus': 495,\n",
       " 'thy': 496,\n",
       " 'tide': 497,\n",
       " 'tight': 498,\n",
       " 'till': 499,\n",
       " 'time': 500,\n",
       " \"time's\": 501,\n",
       " 'tinkle': 502,\n",
       " 'tire': 503,\n",
       " 'to': 504,\n",
       " 'torment': 505,\n",
       " 'torture': 506,\n",
       " 'town': 507,\n",
       " 'trail': 508,\n",
       " 'treatin': 509,\n",
       " 'trouble': 510,\n",
       " 'tumble': 511,\n",
       " 'twas': 512,\n",
       " 'twilight': 513,\n",
       " 'two': 514,\n",
       " 'u': 515,\n",
       " 'unloved': 516,\n",
       " 'until': 517,\n",
       " 'up': 518,\n",
       " 'utter': 519,\n",
       " 'vain': 520,\n",
       " 'vapour': 521,\n",
       " 'vehement': 522,\n",
       " 'visual': 523,\n",
       " 'voice': 524,\n",
       " 'wa': 525,\n",
       " 'wake': 526,\n",
       " 'wall': 527,\n",
       " 'wander': 528,\n",
       " 'want': 529,\n",
       " 'war': 530,\n",
       " 'warlike': 531,\n",
       " 'warn': 532,\n",
       " 'waste': 533,\n",
       " 'watch': 534,\n",
       " 'water': 535,\n",
       " 'waver': 536,\n",
       " 'way': 537,\n",
       " 'we': 538,\n",
       " 'weak': 539,\n",
       " 'weight': 540,\n",
       " 'weird': 541,\n",
       " 'what': 542,\n",
       " 'wheeze': 543,\n",
       " 'when': 544,\n",
       " 'where': 545,\n",
       " 'which': 546,\n",
       " 'while': 547,\n",
       " 'who': 548,\n",
       " 'whole': 549,\n",
       " 'why': 550,\n",
       " 'wild': 551,\n",
       " 'will': 552,\n",
       " 'wilt': 553,\n",
       " 'wind': 554,\n",
       " 'wing': 555,\n",
       " 'winter': 556,\n",
       " 'with': 557,\n",
       " 'wither': 558,\n",
       " 'within': 559,\n",
       " 'woe': 560,\n",
       " 'woman': 561,\n",
       " 'word': 562,\n",
       " 'world': 563,\n",
       " 'worship': 564,\n",
       " 'worthless': 565,\n",
       " 'would': 566,\n",
       " 'wrack': 567,\n",
       " 'wreck': 568,\n",
       " 'wrinkle': 569,\n",
       " 'writ': 570,\n",
       " 'wrong': 571,\n",
       " \"yo'\": 572,\n",
       " 'you': 573,\n",
       " 'your': 574,\n",
       " \"youth's\": 575}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create word-index mappings\n",
    "word_indices = dict((word, index) for index, word in enumerate(unique_words))\n",
    "word_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6413184",
   "metadata": {},
   "source": [
    "### Create Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5afa53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create x (input): Split text into blocks, where each block has the same amount of words\n",
    "# Create y (targets): For each x input, the y is the word that comes next\n",
    "# The model should learn to predict y from the input x\n",
    "\n",
    "block_size = 2\n",
    "step = 1\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for i in range(0, len(word_tokens) - block_size, step):\n",
    "    x.append(word_tokens[i: i+block_size])\n",
    "    y.append(word_tokens[i + block_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83d0d331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['and', 'that'],\n",
       " ['that', 'be'],\n",
       " ['be', 'why'],\n",
       " ['why', 'the'],\n",
       " ['the', 'lonesome']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect x\n",
    "x[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d1dd331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1264"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of blocks\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c87bed",
   "metadata": {},
   "source": [
    "### Create One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ba28e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one-hot encoding of x\n",
    "x_encoded = []\n",
    "\n",
    "for x_arr in x:\n",
    "    x_ints = [word_indices[item] for item in x_arr]\n",
    "    \n",
    "    x_row = []\n",
    "    for item in x_ints:\n",
    "        x_vector = np.zeros(len(unique_words))\n",
    "        x_vector[item] = 1\n",
    "        x_row.append(x_vector)\n",
    "        \n",
    "    x_encoded.append(x_row)\n",
    "    \n",
    "x_encoded = np.array(x_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e351e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['be', 'why', 'the', 'lonesome', 'day']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect y\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea6c112d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37, 550, 471, 268, 101]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert each word in y into their corresponding indices\n",
    "y_ints = [word_indices[item] for item in y]\n",
    "y_ints[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fc0bfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one-hot encoding of y\n",
    "y_encoded = []\n",
    "\n",
    "for item in y_ints:\n",
    "    y_vector = np.zeros(len(unique_words))\n",
    "    y_vector[item] = 1\n",
    "    y_encoded.append(y_vector)\n",
    "\n",
    "y_encoded = np.array(y_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcda4bf",
   "metadata": {},
   "source": [
    "### Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "caa21464",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, block_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embeddings = nn.Linear(input_dim, 2000)\n",
    "        self.hidden = nn.Linear(2000, 1200)\n",
    "        self.output = nn.Linear(1200, output_dim)\n",
    "        \n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.embeddings(x))\n",
    "        x = self.tanh(self.hidden(x))\n",
    "        x = self.softmax(self.output(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6ff9f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1152\n"
     ]
    }
   ],
   "source": [
    "# Get size of input for training the model\n",
    "input_size = x_encoded[0].ravel().shape[0]\n",
    "print(x_encoded[0].ravel().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df58af12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing torch operations on cuda device\n"
     ]
    }
   ],
   "source": [
    "# Allocate tensors to the device used for computation\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Performing torch operations on {device} device\")\n",
    "\n",
    "# Create x and y PyTorch tensors\n",
    "x = torch.tensor(x_encoded).float().to(device)\n",
    "y = torch.tensor(y_encoded).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb023182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextGenerator(\n",
       "  (embeddings): Linear(in_features=1152, out_features=2000, bias=True)\n",
       "  (hidden): Linear(in_features=2000, out_features=1200, bias=True)\n",
       "  (output): Linear(in_features=1200, out_features=576, bias=True)\n",
       "  (tanh): Tanh()\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate model\n",
    "model = TextGenerator(input_size, len(unique_words), block_size).to(device)\n",
    "\n",
    "# Print model configuration\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "433009b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.000000001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98ee59c",
   "metadata": {},
   "source": [
    "### Create Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9e8b60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom Dataset class\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "        self.n_samples = len(x)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index].ravel(), self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9228e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset using custom Dataset class\n",
    "training_ds = CustomDataset(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a488527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training dataset into DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    training_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03558f02",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a82f8538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to train model\n",
    "def train_fn(loader, model, optimizer, loss_fn, device):\n",
    "    loop = tqdm(loader)\n",
    "\n",
    "    ave_loss = 0\n",
    "    count = 0 \n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        \n",
    "        # Forward\n",
    "        predictions = model.forward(data)\n",
    "        loss = loss_fn(predictions, targets)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update tqdm loading bar\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        count += 1\n",
    "        ave_loss += loss.item()\n",
    "    \n",
    "    ave_loss = ave_loss / count\n",
    "\n",
    "    return ave_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7811b5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:03<00:00, 32.41it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356128782737912\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 121.03it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356128595006748\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 117.33it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356128388502467\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 123.05it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.3561281970166785\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 121.72it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356128013040137\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 123.35it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356127772744246\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 118.25it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356127573749212\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 120.61it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356127412300411\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 113.09it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356127209550753\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 115.98it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356127040592704\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 112.89it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356126871634656\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 112.59it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356126672639622\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 114.93it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356126496172327\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 113.49it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356126285913422\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 112.89it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356126068145271\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 114.41it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356125917960339\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 118.47it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356125741493045\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 119.47it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356125527479517\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 118.47it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356125343502976\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 117.92it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356125170790304\n",
      "Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 117.26it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.3561249605314\n",
      "Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 119.25it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356124802837222\n",
      "Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 115.75it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356124577559824\n",
      "Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 121.88it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356124408601776\n",
      "Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 121.53it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356124190833625\n",
      "Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 120.61it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.35612398057472\n",
      "Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 122.35it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356123819125919\n",
      "Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 121.06it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356123593848522\n",
      "Epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 111.01it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356123439908966\n",
      "Epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 115.03it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356123207122322\n",
      "Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 118.69it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356123026900404\n",
      "Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 117.48it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356122876715473\n",
      "Epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 120.38it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.3561226439288285\n",
      "Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 118.91it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.35612248623465\n",
      "Epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 119.30it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.3561222909942385\n",
      "Epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 119.31it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356122103263074\n",
      "Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 119.14it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.3561218704764295\n",
      "Epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 118.58it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356121682745266\n",
      "Epoch: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 119.47it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356121498768724\n",
      "Epoch: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 113.19it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356121311037559\n",
      "Epoch: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 119.59it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356121153343381\n",
      "Epoch: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 118.69it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356120999403826\n",
      "Epoch: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 106.72it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356120736580196\n",
      "Epoch: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 117.16it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356120552603654\n",
      "Epoch: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 118.03it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.35612031981701\n",
      "Epoch: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 117.26it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356120139595092\n",
      "Epoch: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 118.58it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356119903053824\n",
      "Epoch: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 118.25it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356119700304166\n",
      "Epoch: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 114.83it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356119508818378\n",
      "Epoch: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:02<00:00, 55.68it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356119317332591\n",
      "Epoch: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 88.19it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356119114582933\n",
      "Epoch: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 89.94it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356118930606391\n",
      "Epoch: 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 89.75it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.3561188029492\n",
      "Epoch: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 88.44it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356118600199542\n",
      "Epoch: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 89.37it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356118408713754\n",
      "Epoch: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 86.98it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356118194700226\n",
      "Epoch: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 87.34it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356117961913582\n",
      "Epoch: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 88.19it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356117781691664\n",
      "Epoch: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 87.95it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356117567678136\n",
      "Epoch: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 87.89it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356117372437725\n",
      "Epoch: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 87.23it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356117180951937\n",
      "Epoch: 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 86.39it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356116970693033\n",
      "Epoch: 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 87.11it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356116767943375\n",
      "Epoch: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 87.17it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356116614003819\n",
      "Epoch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 86.63it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356116396235668\n",
      "Epoch: 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 86.87it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356116148430531\n",
      "Epoch: 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 86.75it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356115971963237\n",
      "Epoch: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 87.41it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356115746685839\n",
      "Epoch: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 87.11it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356115562709298\n",
      "Epoch: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 86.16it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.3561153374319\n",
      "Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 87.83it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356115187246968\n",
      "Epoch: 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 87.29it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356114984497311\n",
      "Epoch: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 87.77it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356114744201419\n",
      "Epoch: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 87.71it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356114575243372\n",
      "Epoch: 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 83.61it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.35611439126683\n",
      "Epoch: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 86.75it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356114211044912\n",
      "Epoch: 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 87.89it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356113993276761\n",
      "Epoch: 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 87.52it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356113805545597\n",
      "Epoch: 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 87.40it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356113550231212\n",
      "Epoch: 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 88.01it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356113362500048\n",
      "Epoch: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 94.07it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.3561131484865205\n",
      "Epoch: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 109.39it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356112960755356\n",
      "Epoch: 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 106.58it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356112780533437\n",
      "Epoch: 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 107.49it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.35611255525604\n",
      "Epoch: 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 108.74it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356112344997135\n",
      "Epoch: 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 108.72it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356112134738232\n",
      "Epoch: 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 107.82it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356111935743197\n",
      "Epoch: 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 107.87it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356111751766655\n",
      "Epoch: 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 105.82it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356111541507751\n",
      "Epoch: 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 81.41it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356111342512716\n",
      "Epoch: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 83.45it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356111136008435\n",
      "Epoch: 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 86.87it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356110903221791\n",
      "Epoch: 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 88.08it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356110745527613\n",
      "Epoch: 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 88.17it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356110482703983\n",
      "Epoch: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 85.34it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356110328764427\n",
      "Epoch: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 88.33it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356110095977783\n",
      "Epoch: 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 86.19it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356109912001242\n",
      "Epoch: 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 87.61it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.3561097280247\n",
      "Epoch: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 89.17it/s, loss=6.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356109502747303\n",
      "Epoch: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 89.36it/s, loss=6.36]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 6.356109281224529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "epochs = 100\n",
    "average_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    ave_loss = train_fn(train_loader, model, optimizer, criterion, device)\n",
    "    \n",
    "    print(\"Ave Loss: {}\".format(ave_loss))\n",
    "    average_losses.append(ave_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e315a81",
   "metadata": {},
   "source": [
    "### Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2fd9aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inspect probability distribution of word tokens\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "random.seed(2)\n",
    "\n",
    "phrase = [indices_words[random.randint(0, len(unique_words))], indices_words[random.randint(0, len(unique_words))]]\n",
    "x_ints = [word_indices[item] for item in phrase]\n",
    "x_vector = []\n",
    "\n",
    "for item in x_ints:\n",
    "    x_item = np.zeros(len(unique_words))\n",
    "    x_item[item] = 1\n",
    "    x_vector.append(x_item)\n",
    "\n",
    "initial_input = torch.tensor([np.array([x_vector]).ravel()]).to(dtype=torch.float32).to(device)\n",
    "output = model(initial_input)[0].detach().cpu().numpy()\n",
    "\n",
    "df = pd.DataFrame(output)\n",
    "df.plot.bar()\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "140eb6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text sample from model output\n",
    "word_count = 100\n",
    "text = []\n",
    "paragraph_count = 5\n",
    "\n",
    "# Length of phrase should be same as block_size\n",
    "word1, word2 = indices_words[random.randint(0, len(unique_words))], indices_words[random.randint(0, len(unique_words))]\n",
    "\n",
    "for p in range(paragraph_count):\n",
    "    text.append([])\n",
    "    \n",
    "    for i in range(word_count):\n",
    "        phrase = [word1, word2]\n",
    "        x_ints = [word_indices[item] for item in phrase]\n",
    "        x_vector = []\n",
    "\n",
    "        for item in x_ints:\n",
    "            x_item = np.zeros(len(unique_words))\n",
    "            x_item[item] = 1\n",
    "            x_vector.append(x_item)\n",
    "\n",
    "        initial_input = torch.tensor([np.array([x_vector]).ravel()]).float().to(device)\n",
    "\n",
    "        output = model(initial_input)[0].detach().cpu().numpy()\n",
    "\n",
    "        # Workaround to fix occasional sum(pvals[:-1]) > 1.0  bug from implicit casting in np.random.multinomial \n",
    "        output = output.astype(float)\n",
    "        output /= output.sum()\n",
    "\n",
    "        index = np.where(np.random.multinomial(1, output) == 1)[0][0]\n",
    "        word3 = indices_words[index]\n",
    "        text[p].append(word3)\n",
    "\n",
    "        # Use generated word from this run as seed for next run\n",
    "        word1, word2 = word2, word3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5bd566b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Paragraph 0:\n",
      "live forelaid more silk nail death future strive watch no dread gloom darkness mood gray howl sitteth satrap thine they fury nice stock receave then be false runt slay solemn lose always ago breast dark enough trouble sharp regin because o dread our teach wild thousand moment rude moment blast land two inand accomplish give run fountain a lone wreck tinkle sleep throb flight nice offspring scare mood around word distress dawn if fetter bear then throb dark home maidenhead fer clatter know face augur vapour most ripe him delusive darkness groom fetter lave on dare for etch mile mourn\n",
      "\n",
      "\n",
      "Generated Paragraph 1:\n",
      "star name into rough or moloch say roll tire nice rage morn stifle on how moan sword thing shepherd thy ripe lave slay might captive's utter child shadow i melt stiff blankness end fight pathetic quicken monster darkness god etch nerve ruin pathetic lap could face dread stifle god's tight hate featureless dawn ridiculous 'twas away must morn featureless may bear monkey break wild angel behold hi within bad inclose sweep shrill calumny open nothing wa future beam she what cross lie glance vain once blindness droop this haunt live utter waver live sad behold fraud glen afar lift great\n",
      "\n",
      "\n",
      "Generated Paragraph 2:\n",
      "and bow blindness barn pity scatter scatter sophist echo twas threaten steal wilt hearthstone wrack folly generation than lucrece thee dumb human perish silk crush disunion unloved forlorn burn nerve monstrous ago ne'er faint groom watch maidenhead down wrong flight weak struggle discontent each than enemy weird infernal whole such an' blast inclose wind earth thus none silly pursue these beat human fall future augur some moloch inand lowly eye gaud guard woman ah line thousand slavery end on ruin inand accomplish deaf him here guile end blind nothing war wither pursue friend corps pity sorrow eye open rave prison\n",
      "\n",
      "\n",
      "Generated Paragraph 3:\n",
      "would weird multiply still slave law stifle pain answer our vehement future cough may sorrowful make cross spake moloch melt howl despair know load get pathetic heavy thus e'en gun let teach torment life heap but head liveliest madness mole echo poor curse selfishness teach load look generation weight guard word up blend hand hang 'twas fraud satrap star life shrill from lonesome open them shepherd spoil lord barn slavery despair law death way get one future scorn house cloudy obliterate priest torment see sword echo pang dwell an world thro than sorrowful hope watch fool tempest slumber hell but\n",
      "\n",
      "\n",
      "Generated Paragraph 4:\n",
      "barn steal whole ah wilt nerve pillar selfishness melancholy smile hang cross lave blast sleep moon fill pu barn bleed her may mine life than ridiculous warn cold some one fetter pain more may torture shrill house fray till on while death's forcd mile angel monster pathetic stock off down make pursue guile foggy gaud lay future bind an' save visual cloud then priest most foe humanness of stifle nerve thine solemn goad take 'twas trail her shore bear quicken old i've not wander beat at gallic she bat prison fiery dip cruell know co within meditate satrap foggy within\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for p in range(paragraph_count):\n",
    "    print(f\"Generated Paragraph {p}:\")\n",
    "    print(' '.join(text[p]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d46cb7",
   "metadata": {},
   "source": [
    "### Create Feature Vectors from Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7342e5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['and', 'that', 'be', 'why', 'the', 'lonesome', 'day'],\n",
       " ['and', 'so', 'on', 'then', 'a', 'worthless', 'gaud', 'or', 'two'],\n",
       " ['sound', \"o'er\", 'earth', 'and', 'sea', 'it', 'blast', 'of', 'war'],\n",
       " ['want', 'and', 'woe', 'which', 'torture', 'u'],\n",
       " ['an', 'echo', 'return', 'on', 'the', 'cold', 'gray', 'morn'],\n",
       " ['while', 'i', 'i', 'build', 'up', 'folly', 'like', 'a', 'wall'],\n",
       " ['ah', 'what', 'a', 'pang', 'of', 'ache', 'sharp', 'surprise'],\n",
       " ['and', 'the', 'old', 'swallow', 'haunt', 'barn'],\n",
       " ['the', 'which', 'she', 'bear', 'home', 'it', 'burn', 'her', 'nest'],\n",
       " ['the', 'crown', 'of', 'sorrow', 'on', 'their', 'head', 'their', 'loss'],\n",
       " ['i', 'lay', 'and', 'watch', 'the', 'lonely', 'gloom'],\n",
       " ['a', 'sceptremonstrous', 'wing', 'intolerable'],\n",
       " ['while', 'the', 'rude', 'wind', 'blow', 'off', 'each', 'shadowy', 'crown'],\n",
       " ['but', 'o', 'nevermore', 'can', 'we', 'prison', 'him', 'tight'],\n",
       " ['may', 'meditate', 'a', 'whole', \"youth's\", 'loss'],\n",
       " ['when', 'thee', 'the', 'eye', 'of', 'that', 'harsh', 'long', 'ago'],\n",
       " ['the', 'foe', 'inclose', 'and', 'his', 'friend', 'pursue'],\n",
       " ['and',\n",
       "  'bow',\n",
       "  'to',\n",
       "  'dread',\n",
       "  'inquisitor',\n",
       "  'and',\n",
       "  'worship',\n",
       "  'lord',\n",
       "  'of',\n",
       "  'dust'],\n",
       " ['mile', 'off', 'three', 'dangerous', 'mile', 'be', 'home'],\n",
       " ['else', 'sufferd', 'it', 'will', 'set', 'the', 'heart', 'on', 'fire'],\n",
       " ['what', 'god', 'what', 'madness', 'hither', 'steerd', 'your', 'course'],\n",
       " ['when', 'the', 'glance', 'hast', 'lose', 'it', 'beam'],\n",
       " ['in', 'the', 'shadow', 'of', 'the', 'shore', 'a', 'dead', 'leaf', 'wake'],\n",
       " ['thy', 'sleep', 'make', 'ridiculous'],\n",
       " ['mine', 'eye', 'be', 'of', 'their', 'madness', 'half', 'beguile'],\n",
       " ['you', \"sha'\", \"n't\", 'roll', \"yo'\", 'eye', 'at', 'me'],\n",
       " ['from', 'flight', 'seditious', 'angel', 'to', 'receave'],\n",
       " ['afar', 'the', 'melancholy', 'thunder', 'moan'],\n",
       " ['their', 'hate', 'and', 'selfishness', 'and', 'pride'],\n",
       " ['and', 'sorrowful', 'to', 'day', 'thy', 'child', 'set'],\n",
       " ['save', 'for', 'a', 'cry', 'that', 'echo', 'shrill'],\n",
       " ['the', 'adulterate', 'death', 'of', 'lucrece', 'and', 'her', 'groom'],\n",
       " ['to', 'accomplish', 'suicide'],\n",
       " ['each', 'by', 'his', 'fiery', 'torture', 'howl', 'and', 'rave'],\n",
       " ['at', 'once', 'come', 'tumble', 'down', 'the', 'rocky', 'wall'],\n",
       " ['sit', 'mournfully', 'guard', 'their', 'corps', 'there'],\n",
       " ['twas', 'when', 'you', 'steal', 'my', 'maidenhead'],\n",
       " ['flood', 'his', 'black', 'hearthstone', 'till', 'it', 'flame', 'expire'],\n",
       " ['men', 'say', 'into', 'a', 'smile', 'which', 'guile', 'portend'],\n",
       " ['deaf', 'and', 'dumb', 'and', 'blind', 'and', 'cold'],\n",
       " ['the', 'visual', 'nerve', 'be', 'wither', 'to', 'the', 'root'],\n",
       " ['there', 'be', 'nothing', 'to', 'hope', 'for', 'i', 'be', 'tire'],\n",
       " ['have', 'see', 'the', 'danger', 'which', 'i', 'dare', 'not', 'look'],\n",
       " ['all', 'foredoom', 'to', 'melt', 'away'],\n",
       " ['but',\n",
       "  'throw',\n",
       "  'in',\n",
       "  'a',\n",
       "  'heap',\n",
       "  'with',\n",
       "  'a',\n",
       "  'crush',\n",
       "  'and',\n",
       "  'a',\n",
       "  'clatter'],\n",
       " ['but', 'homesick', 'tear', 'would', 'fill', 'the', 'eye'],\n",
       " ['of', 'course', 'throw', 'monstrous', 'shadows:', 'those', 'who', 'think'],\n",
       " ['the', 'mad', 'briareus', 'of', 'disunion', 'rise'],\n",
       " ['i', 'see', 'them', 'tear', 'by', 'gallic', 'gun'],\n",
       " ['thou', \"feel'st\", 'it', 'burn', 'in', 'and', 'inand', 'fear'],\n",
       " ['but', 'all', 'of', 'them', 'be', 'bad', 'enough'],\n",
       " ['ha', 'it', 'become', 'to', 'thee', 'a', 'labyrinth', 'never', 'end'],\n",
       " ['on', 'her', 'change', 'world', 'of', 'ruin', 'waste', 'and', 'wrack'],\n",
       " ['kneel', \"ne'er\", 'spoil', 'silk', 'stock', 'quit', 'thy', 'state'],\n",
       " ['from', 'earth', 'with', 'the', 'water', 'of', 'pain'],\n",
       " ['be', 'writ', 'in', 'mood', 'and', 'frown', 'and', 'wrinkle', 'strange'],\n",
       " ['those', 'cobweb', 'nerve', 'he', 'could', 'not', 'dull', 'within'],\n",
       " ['fool', 'with', 'your', 'promise'],\n",
       " ['thy', 'mission', 'to', 'a', 'world', 'of', 'woe'],\n",
       " ['our', 'frown', 'foeman', 'of', 'the', 'night'],\n",
       " ['when', 'dreadful', 'to', 'behold', 'from', 'sea', 'we', 'spy'],\n",
       " ['some', 'moment', 'nail', 'on', \"sorrow's\", 'cross'],\n",
       " ['the', 'nymph', 'who', 'scatter', 'flame', 'fire', 'around'],\n",
       " ['for',\n",
       "  \"'twas\",\n",
       "  \"e'en\",\n",
       "  'a',\n",
       "  'a',\n",
       "  'great',\n",
       "  \"god's\",\n",
       "  'slay',\n",
       "  'and',\n",
       "  'they',\n",
       "  'fear',\n",
       "  'the',\n",
       "  'wrath',\n",
       "  'of',\n",
       "  'the',\n",
       "  'sky'],\n",
       " ['and', \"i've\", 'be', 'like', 'that', 'silly', 'girl'],\n",
       " ['to', 'make', 'a', 'body', 'curse'],\n",
       " ['be', 'murmur', 'on', 'the', 'stifle', 'air'],\n",
       " ['how', 'poor', 'these', 'pallid', 'phrase', 'seem'],\n",
       " ['these', 'monster', 'set', 'out', 'in', 'the', 'open', 'sun'],\n",
       " ['blindness', 'like', 'that', 'would', 'scare', 'the', 'mole', 'and', 'bat'],\n",
       " ['do', 'from', 'the', 'altar', 'steal', 'a', 'smoulder', 'brand'],\n",
       " ['be', 'beat', 'by', 'the', 'wind', 'with', 'foggy', 'vapour', 'bind'],\n",
       " ['until', 'the', 'bitter', 'summon', 'fell'],\n",
       " ['in', 'slumber', 'for', 'thine', 'enemy', 'never', 'sleep'],\n",
       " ['if', 'men', 'be', 'always', 'at', 'a', 'loss'],\n",
       " ['with', 'warn', 'cough', 'and', 'threaten', 'wheeze'],\n",
       " ['daily', 'struggle', 'though', 'unloved', 'and', 'lonely'],\n",
       " ['how', 'heavy', 'it', 'seem', 'a', 'heavy', 'a', 'a', 'stone'],\n",
       " ['heart', 'a', 'though', 'with', 'ash', 'blend'],\n",
       " ['pass', 'to', 'lap', 'thy', 'water', 'crush', 'the', 'flower'],\n",
       " ['his', 'hand', 'the', \"captive's\", 'fetter', 'break'],\n",
       " ['get',\n",
       "  'the',\n",
       "  'ill',\n",
       "  'name',\n",
       "  'of',\n",
       "  'augur',\n",
       "  'because',\n",
       "  'they',\n",
       "  'be',\n",
       "  'bore',\n",
       "  '—'],\n",
       " ['then', 'thro', 'his', 'breast', 'his', 'fatal', 'sword', 'he', 'send'],\n",
       " ['the', 'pain', 'when', 'it', 'do', 'live'],\n",
       " ['soft', 'discontent', 'eye'],\n",
       " ['and', 'the', 'rude', 'people', 'rage', 'with', 'ignorant', 'cry'],\n",
       " ['o', 'lord', 'that', 'didst', 'smother', 'mankind', 'in', 'thy', 'flood'],\n",
       " ['be', 'this', 'a', 'time', 'to', 'be', 'cloudy', 'and', 'sad'],\n",
       " ['blood', 'dip', 'arrow', 'which', 'savage', 'make'],\n",
       " ['the', 'moon', 'and', 'the', 'star', 'be', 'anxious'],\n",
       " ['in',\n",
       "  'the',\n",
       "  'twilight',\n",
       "  'of',\n",
       "  'age',\n",
       "  'all',\n",
       "  'thing',\n",
       "  'seem',\n",
       "  'strange',\n",
       "  'and',\n",
       "  'phantasmal'],\n",
       " ['a', 'wild', 'and', 'stormy', 'sea'],\n",
       " ['dark', 'with', 'more', 'cloud', 'than', 'tempest', 'be'],\n",
       " ['here',\n",
       "  'come',\n",
       "  'the',\n",
       "  'cripple',\n",
       "  'jane',\n",
       "  'and',\n",
       "  'by',\n",
       "  'a',\n",
       "  \"fountain's\",\n",
       "  'side'],\n",
       " ['which', 'goad', 'him', 'in', 'his', 'distress'],\n",
       " ['forelaid', 'and', 'take', 'while', 'he', 'strive', 'in', 'vain'],\n",
       " ['when', 'blight', 'wa', 'nearest'],\n",
       " ['pillar', 'by', 'madness', 'multiply'],\n",
       " ['no', 'rest', 'that', 'throb', 'slave', 'may', 'ask'],\n",
       " [\"o'er\", \"time's\", 'delusive', 'tide'],\n",
       " ['no',\n",
       "  'word',\n",
       "  'for',\n",
       "  'a',\n",
       "  'while',\n",
       "  'spake',\n",
       "  'regin',\n",
       "  'but',\n",
       "  'he',\n",
       "  'hang',\n",
       "  'his',\n",
       "  'head',\n",
       "  'adown'],\n",
       " ['envy', 'and', 'calumny', 'and', 'hate', 'and', 'pain'],\n",
       " ['and', 'murmur', 'a', 'strange', 'and', 'solemn', 'air'],\n",
       " ['teach', 'by', 'the', 'sorrow', 'that', 'his', 'age', 'have', 'know'],\n",
       " ['let',\n",
       "  'sophist',\n",
       "  'give',\n",
       "  'the',\n",
       "  'lie',\n",
       "  'heart',\n",
       "  'droop',\n",
       "  'and',\n",
       "  'courtier',\n",
       "  'play',\n",
       "  'the',\n",
       "  'worm'],\n",
       " ['the', 'fraud', 'of', 'priest', 'the', 'wrong', 'of', 'law'],\n",
       " ['obliterate', 'the', 'etch'],\n",
       " ['and', 'leaf', 'the', 'world', 'to', 'darkness', 'and', 'to', 'me'],\n",
       " ['that', 'satrap', 'would', 'have', 'shiver', 'at', 'his', 'frown'],\n",
       " ['harsh', 'featureless', 'and', 'rude', 'barrenly', 'perish:'],\n",
       " [\"oblivion's\", 'blankness', 'claim'],\n",
       " ['torment', 'by', 'the', 'quicken', 'blood', 'of', 'root'],\n",
       " ['where',\n",
       "  'the',\n",
       "  'cloudy',\n",
       "  'hang',\n",
       "  'waver',\n",
       "  'and',\n",
       "  'the',\n",
       "  'flicker',\n",
       "  'shadow',\n",
       "  'fall'],\n",
       " ['leave',\n",
       "  'the',\n",
       "  'tear',\n",
       "  'human',\n",
       "  'heart',\n",
       "  'their',\n",
       "  'food',\n",
       "  'and',\n",
       "  'dwell',\n",
       "  'place'],\n",
       " ['inexorable', 'death', 'and', 'claim', 'his', 'right'],\n",
       " ['trail', 'wreck', 'it', 'come', 'to', 'land'],\n",
       " ['dead', 'among', 'the', 'shout', 'people'],\n",
       " ['from',\n",
       "  'the',\n",
       "  'slaughter',\n",
       "  'of',\n",
       "  'my',\n",
       "  'offspring',\n",
       "  'and',\n",
       "  'the',\n",
       "  'spoil',\n",
       "  'of',\n",
       "  'my',\n",
       "  'land'],\n",
       " ['no', 'answer', 'come', 'but', 'faint', 'and', 'forlorn'],\n",
       " ['and', 'heavy', 'a', 'the', 'dead'],\n",
       " ['a', 'woman', 'ha', 'be', 'strangle', 'with', 'le', 'weight:'],\n",
       " ['howl', 'through', 'the', 'dark', 'like', 'sound', 'from', 'hell'],\n",
       " ['trouble', 'with', 'life', 'the', 'water', 'of', 'the', 'world'],\n",
       " ['and', 'the', 'word', 'which', 'he', 'utter', 'be', 'worship', 'or', 'die'],\n",
       " ['the', 'weird', 'pathetic', 'scarlet', 'of', 'day', 'dawn'],\n",
       " ['but',\n",
       "  'your',\n",
       "  'dead',\n",
       "  'ripe',\n",
       "  'one',\n",
       "  'range',\n",
       "  'high',\n",
       "  'fer',\n",
       "  \"treatin'\",\n",
       "  'nothun',\n",
       "  'bretherin'],\n",
       " ['it', 'be', 'a', 'lie', 'a', 'damn', 'infernal', 'lie'],\n",
       " ['and', 'after', 'that', 'the', 'winter', 'cold', 'and', 'drear'],\n",
       " ['thus', 'hee', 'in', 'scorn', 'the', 'warlike', 'angel', \"mov'd\"],\n",
       " ['false', 'face', 'hang', 'on', 'string'],\n",
       " ['that',\n",
       "  'in',\n",
       "  'their',\n",
       "  'life',\n",
       "  'such',\n",
       "  'deadly',\n",
       "  'fray',\n",
       "  'they',\n",
       "  \"ne'er\",\n",
       "  'have',\n",
       "  'see',\n",
       "  'before'],\n",
       " ['her', 'not', 'nice', 'load'],\n",
       " ['and', 'fear', 'be', 'add', 'and', 'avenge', 'flame'],\n",
       " ['and', 'stiff', 'in', 'fight', 'but', 'serious', \"drill's\", 'despair'],\n",
       " ['till', 'the', 'deaf', 'fury', 'come', 'your', 'house', 'to', 'sweep', \"'\"],\n",
       " ['but', 'now', 'i', 'see', 'most', 'cruell', 'hee'],\n",
       " ['how', 'weak', 'this', 'tinkle', 'line'],\n",
       " ['and', 'make', 'the', 'liveliest', 'monkey', 'melancholy'],\n",
       " ['where', 'the', 'moloch', 'of', 'slavery', 'sitteth', 'on', 'high'],\n",
       " ['for', 'wander', 'sad', 'and', 'lone'],\n",
       " ['none',\n",
       "  'will',\n",
       "  'forget',\n",
       "  'it',\n",
       "  'till',\n",
       "  'shall',\n",
       "  'fall',\n",
       "  'the',\n",
       "  'deadly',\n",
       "  'dart'],\n",
       " ['forever', 'quiver', \"o'er\", 'his', 'task'],\n",
       " ['wilt',\n",
       "  'thou',\n",
       "  'our',\n",
       "  'lowly',\n",
       "  'bed',\n",
       "  'with',\n",
       "  'tear',\n",
       "  'of',\n",
       "  'pity',\n",
       "  'lave',\n",
       "  \"'\"],\n",
       " ['and', 'seek', 'the', 'danger', 'i', 'wa', 'forcd', 'to', 'shun'],\n",
       " ['down', 'the', 'dark', 'future', 'through', 'long', 'generation'],\n",
       " ['but', 'she', 'always', 'run', 'away', 'and', 'leave'],\n",
       " ['with', 'such', 'vehement', 'force', 'and', 'might'],\n",
       " ['vain', 'cry', 'throughout', 'the', 'street', 'thousand', 'pursue'],\n",
       " ['and', 'all', 'their', 'echo', 'mourn'],\n",
       " ['still', 'must', 'mine', 'though', 'bleed', 'beat'],\n",
       " ['in', 'town', \"an'\", 'not', 'the', 'leanest', 'runt'],\n",
       " ['by', \"death's\", 'frequent', 'way'],\n",
       " ['rejection', 'of', 'his', 'humanness'],\n",
       " ['faint', 'voice', 'lift', 'shrill', 'with', 'pain'],\n",
       " ['in', 'the', 'wild', 'glen', 'rough', 'shepherd', 'will', 'deplore']]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = []\n",
    "\n",
    "# Tokenize by line\n",
    "for index, row in negative.iterrows():\n",
    "    tokenized_row = row['Text'].split(' ')\n",
    "    \n",
    "    # Preprocess using the same settings as preprocessing done before training model\n",
    "    tokenized_row = regexp_tokenize(' '.join(tokenized_row), pattern=r'[^\\S\\r]+|[\\.,;!?()--_\"]', gaps=True)\n",
    "    tokenized_row = [lemmatizer.lemmatize(token) for token in tokenized_row] # Lemmatize nouns\n",
    "    tokenized_row = [lemmatizer.lemmatize(token, 'v') for token in tokenized_row] # Lemmatize verbs\n",
    "    \n",
    "    sentences.append(tokenized_row)\n",
    "    \n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "227e0dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = 100\n",
    "w2v_model = Word2Vec(sentences, vector_size=vector_size, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d010c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 588\n"
     ]
    }
   ],
   "source": [
    "vocab = w2v_model.wv.index_to_key\n",
    "vocab_length = len(vocab)\n",
    "\n",
    "print(f'Vocabulary Size: {format(vocab_length)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6d8b0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'and',\n",
       " 'a',\n",
       " 'of',\n",
       " 'be',\n",
       " 'to',\n",
       " 'in',\n",
       " 'his',\n",
       " 'with',\n",
       " 'it',\n",
       " 'that',\n",
       " 'but',\n",
       " 'on',\n",
       " 'by',\n",
       " 'their',\n",
       " 'i',\n",
       " 'which',\n",
       " 'thy',\n",
       " 'from',\n",
       " 'when',\n",
       " 'for',\n",
       " 'eye',\n",
       " 'come',\n",
       " 'he',\n",
       " 'dead',\n",
       " 'while',\n",
       " 'see',\n",
       " 'like',\n",
       " 'at',\n",
       " 'make',\n",
       " 'world',\n",
       " 'heart',\n",
       " 'tear',\n",
       " 'your',\n",
       " 'pain',\n",
       " 'her',\n",
       " 'all',\n",
       " 'have',\n",
       " 'not',\n",
       " 'how',\n",
       " 'seem',\n",
       " 'rude',\n",
       " 'loss',\n",
       " 'fear',\n",
       " 'heavy',\n",
       " 'dark',\n",
       " 'hang',\n",
       " 'will',\n",
       " 'though',\n",
       " 'set',\n",
       " 'would',\n",
       " 'madness',\n",
       " 'lie',\n",
       " 'cry',\n",
       " 'no',\n",
       " 'sea',\n",
       " 'cold',\n",
       " \"o'er\",\n",
       " 'frown',\n",
       " 'strange',\n",
       " 'echo',\n",
       " 'till',\n",
       " 'day',\n",
       " 'what',\n",
       " 'they',\n",
       " 'flame',\n",
       " 'my',\n",
       " 'water',\n",
       " 'torture',\n",
       " 'woe',\n",
       " 'crush',\n",
       " 'always',\n",
       " 'cloudy',\n",
       " 'shadow',\n",
       " 'shrill',\n",
       " 'course',\n",
       " 'claim',\n",
       " 'where',\n",
       " 'sad',\n",
       " 'fall',\n",
       " 'leave',\n",
       " 'fire',\n",
       " 'blood',\n",
       " 'there',\n",
       " 'death',\n",
       " 'those',\n",
       " 'people',\n",
       " 'burn',\n",
       " 'leaf',\n",
       " 'me',\n",
       " 'hate',\n",
       " 'root',\n",
       " 'melancholy',\n",
       " 'our',\n",
       " 'danger',\n",
       " 'angel',\n",
       " 'word',\n",
       " 'wa',\n",
       " 'then',\n",
       " 'steal',\n",
       " 'or',\n",
       " 'throw',\n",
       " 'this',\n",
       " 'sound',\n",
       " 'you',\n",
       " 'vain',\n",
       " 'nerve',\n",
       " 'mine',\n",
       " 'away',\n",
       " 'earth',\n",
       " 'sleep',\n",
       " 'mile',\n",
       " 'land',\n",
       " 'who',\n",
       " \"'\",\n",
       " 'thou',\n",
       " 'we',\n",
       " 'o',\n",
       " 'hee',\n",
       " 'men',\n",
       " 'each',\n",
       " 'off',\n",
       " 'wind',\n",
       " 'down',\n",
       " 'such',\n",
       " 'deadly',\n",
       " 'these',\n",
       " 'wild',\n",
       " 'age',\n",
       " 'air',\n",
       " 'lonely',\n",
       " 'ha',\n",
       " 'murmur',\n",
       " 'never',\n",
       " 'head',\n",
       " 'she',\n",
       " 'sorrow',\n",
       " 'crown',\n",
       " 'home',\n",
       " 'lord',\n",
       " 'him',\n",
       " 'may',\n",
       " 'life',\n",
       " 'worship',\n",
       " 'beat',\n",
       " 'faint',\n",
       " 'spoil',\n",
       " 'flood',\n",
       " 'pursue',\n",
       " 'deaf',\n",
       " 'through',\n",
       " \"ne'er\",\n",
       " 'do',\n",
       " 'howl',\n",
       " 'long',\n",
       " 'harsh',\n",
       " 'thee',\n",
       " 'them',\n",
       " 'wall',\n",
       " 'high',\n",
       " 'portend',\n",
       " 'hearthstone',\n",
       " 'say',\n",
       " 'blind',\n",
       " 'visual',\n",
       " 'guile',\n",
       " 'expire',\n",
       " 'dumb',\n",
       " 'into',\n",
       " 'nothing',\n",
       " 'wither',\n",
       " 'smile',\n",
       " 'mad',\n",
       " 'hope',\n",
       " 'tire',\n",
       " 'become',\n",
       " 'labyrinth',\n",
       " 'end',\n",
       " 'change',\n",
       " 'ruin',\n",
       " 'waste',\n",
       " 'wrack',\n",
       " 'kneel',\n",
       " 'silk',\n",
       " 'stock',\n",
       " 'quit',\n",
       " 'state',\n",
       " 'writ',\n",
       " 'mood',\n",
       " 'wrinkle',\n",
       " 'cobweb',\n",
       " 'could',\n",
       " 'enough',\n",
       " 'bad',\n",
       " 'inand',\n",
       " 'fill',\n",
       " 'dare',\n",
       " 'look',\n",
       " 'foredoom',\n",
       " 'melt',\n",
       " 'heap',\n",
       " 'clatter',\n",
       " 'homesick',\n",
       " 'monstrous',\n",
       " \"feel'st\",\n",
       " 'shadows:',\n",
       " 'think',\n",
       " 'briareus',\n",
       " 'disunion',\n",
       " 'rise',\n",
       " 'gallic',\n",
       " 'gun',\n",
       " 'black',\n",
       " \"yo'\",\n",
       " 'maidenhead',\n",
       " 'swallow',\n",
       " 'barn',\n",
       " 'bear',\n",
       " 'nest',\n",
       " 'lay',\n",
       " 'watch',\n",
       " 'gloom',\n",
       " 'sceptremonstrous',\n",
       " 'wing',\n",
       " 'intolerable',\n",
       " 'blow',\n",
       " 'shadowy',\n",
       " 'nevermore',\n",
       " 'can',\n",
       " 'prison',\n",
       " 'tight',\n",
       " 'meditate',\n",
       " 'whole',\n",
       " \"youth's\",\n",
       " 'ago',\n",
       " 'foe',\n",
       " 'inclose',\n",
       " 'haunt',\n",
       " 'old',\n",
       " 'bow',\n",
       " 'surprise',\n",
       " 'why',\n",
       " 'lonesome',\n",
       " 'so',\n",
       " 'worthless',\n",
       " 'gaud',\n",
       " 'two',\n",
       " 'blast',\n",
       " 'war',\n",
       " 'want',\n",
       " 'u',\n",
       " 'an',\n",
       " 'return',\n",
       " 'gray',\n",
       " 'morn',\n",
       " 'build',\n",
       " 'up',\n",
       " 'folly',\n",
       " 'ah',\n",
       " 'pang',\n",
       " 'ache',\n",
       " 'sharp',\n",
       " 'friend',\n",
       " 'dread',\n",
       " 'twas',\n",
       " 'receave',\n",
       " 'thunder',\n",
       " 'moan',\n",
       " 'selfishness',\n",
       " 'pride',\n",
       " 'sorrowful',\n",
       " 'child',\n",
       " 'save',\n",
       " 'adulterate',\n",
       " 'lucrece',\n",
       " 'groom',\n",
       " 'accomplish',\n",
       " 'suicide',\n",
       " 'fiery',\n",
       " 'rave',\n",
       " 'once',\n",
       " 'tumble',\n",
       " 'rocky',\n",
       " 'sit',\n",
       " 'mournfully',\n",
       " 'guard',\n",
       " 'corps',\n",
       " 'afar',\n",
       " 'seditious',\n",
       " 'inquisitor',\n",
       " 'flight',\n",
       " 'dust',\n",
       " 'three',\n",
       " 'dangerous',\n",
       " 'else',\n",
       " 'sufferd',\n",
       " 'god',\n",
       " 'hither',\n",
       " 'steerd',\n",
       " 'glance',\n",
       " 'hast',\n",
       " 'lose',\n",
       " 'beam',\n",
       " 'shore',\n",
       " 'wake',\n",
       " 'ridiculous',\n",
       " 'half',\n",
       " 'beguile',\n",
       " \"sha'\",\n",
       " \"n't\",\n",
       " 'roll',\n",
       " 'within',\n",
       " 'dull',\n",
       " 'deplore',\n",
       " 'fool',\n",
       " 'utter',\n",
       " 'ripe',\n",
       " 'dawn',\n",
       " 'scarlet',\n",
       " 'pathetic',\n",
       " 'weird',\n",
       " 'die',\n",
       " 'trouble',\n",
       " 'fray',\n",
       " 'hell',\n",
       " 'weight:',\n",
       " 'le',\n",
       " 'strangle',\n",
       " 'woman',\n",
       " 'forlorn',\n",
       " 'one',\n",
       " 'range',\n",
       " 'fer',\n",
       " \"treatin'\",\n",
       " 'nothun',\n",
       " 'bretherin',\n",
       " 'damn',\n",
       " 'infernal',\n",
       " 'after',\n",
       " 'winter',\n",
       " 'drear',\n",
       " 'thus',\n",
       " 'scorn',\n",
       " 'warlike',\n",
       " \"mov'd\",\n",
       " 'false',\n",
       " 'face',\n",
       " 'answer',\n",
       " 'offspring',\n",
       " 'slaughter',\n",
       " 'perish:',\n",
       " 'courtier',\n",
       " 'play',\n",
       " 'worm',\n",
       " 'fraud',\n",
       " 'priest',\n",
       " 'wrong',\n",
       " 'law',\n",
       " 'obliterate',\n",
       " 'etch',\n",
       " 'darkness',\n",
       " 'satrap',\n",
       " 'shiver',\n",
       " 'featureless',\n",
       " 'barrenly',\n",
       " \"oblivion's\",\n",
       " 'shout',\n",
       " 'blankness',\n",
       " 'torment',\n",
       " 'quicken',\n",
       " 'waver',\n",
       " 'flicker',\n",
       " 'human',\n",
       " 'food',\n",
       " 'dwell',\n",
       " 'place',\n",
       " 'inexorable',\n",
       " 'right',\n",
       " 'trail',\n",
       " 'wreck',\n",
       " 'among',\n",
       " 'string',\n",
       " 'before',\n",
       " 'promise',\n",
       " 'run',\n",
       " 'thousand',\n",
       " 'street',\n",
       " 'throughout',\n",
       " 'might',\n",
       " 'force',\n",
       " 'vehement',\n",
       " 'generation',\n",
       " 'nice',\n",
       " 'future',\n",
       " 'shun',\n",
       " 'forcd',\n",
       " 'seek',\n",
       " 'lave',\n",
       " 'pity',\n",
       " 'mourn',\n",
       " 'still',\n",
       " 'must',\n",
       " 'bleed',\n",
       " 'town',\n",
       " \"an'\",\n",
       " 'leanest',\n",
       " 'runt',\n",
       " \"death's\",\n",
       " 'frequent',\n",
       " 'way',\n",
       " 'rejection',\n",
       " 'humanness',\n",
       " 'voice',\n",
       " 'lift',\n",
       " 'glen',\n",
       " 'rough',\n",
       " 'bed',\n",
       " 'lowly',\n",
       " 'wilt',\n",
       " 'weak',\n",
       " 'load',\n",
       " 'add',\n",
       " 'avenge',\n",
       " 'stiff',\n",
       " 'fight',\n",
       " 'serious',\n",
       " \"drill's\",\n",
       " 'despair',\n",
       " 'fury',\n",
       " 'house',\n",
       " 'sweep',\n",
       " 'now',\n",
       " 'most',\n",
       " 'cruell',\n",
       " 'tinkle',\n",
       " 'task',\n",
       " 'line',\n",
       " 'liveliest',\n",
       " 'monkey',\n",
       " 'moloch',\n",
       " 'slavery',\n",
       " 'sitteth',\n",
       " 'wander',\n",
       " 'lone',\n",
       " 'none',\n",
       " 'forget',\n",
       " 'shall',\n",
       " 'dart',\n",
       " 'forever',\n",
       " 'quiver',\n",
       " 'droop',\n",
       " 'give',\n",
       " 'sophist',\n",
       " 'foggy',\n",
       " 'fell',\n",
       " 'summon',\n",
       " 'bitter',\n",
       " 'until',\n",
       " 'bind',\n",
       " 'vapour',\n",
       " 'brand',\n",
       " 'let',\n",
       " 'smoulder',\n",
       " 'altar',\n",
       " 'bat',\n",
       " 'mole',\n",
       " 'scare',\n",
       " 'blindness',\n",
       " 'slumber',\n",
       " 'thine',\n",
       " 'enemy',\n",
       " 'if',\n",
       " 'warn',\n",
       " 'cough',\n",
       " 'threaten',\n",
       " 'wheeze',\n",
       " 'daily',\n",
       " 'struggle',\n",
       " 'unloved',\n",
       " 'stone',\n",
       " 'ash',\n",
       " 'blend',\n",
       " 'pass',\n",
       " 'lap',\n",
       " 'flower',\n",
       " 'sun',\n",
       " 'open',\n",
       " 'out',\n",
       " \"'twas\",\n",
       " 'mission',\n",
       " 'foeman',\n",
       " 'night',\n",
       " 'dreadful',\n",
       " 'behold',\n",
       " 'spy',\n",
       " 'some',\n",
       " 'moment',\n",
       " 'nail',\n",
       " \"sorrow's\",\n",
       " 'cross',\n",
       " 'nymph',\n",
       " 'scatter',\n",
       " 'around',\n",
       " \"e'en\",\n",
       " 'monster',\n",
       " 'shepherd',\n",
       " \"god's\",\n",
       " 'slay',\n",
       " 'wrath',\n",
       " 'sky',\n",
       " \"i've\",\n",
       " 'silly',\n",
       " 'girl',\n",
       " 'body',\n",
       " 'curse',\n",
       " 'stifle',\n",
       " 'poor',\n",
       " 'pallid',\n",
       " 'phrase',\n",
       " 'hand',\n",
       " \"captive's\",\n",
       " 'fetter',\n",
       " 'multiply',\n",
       " 'tempest',\n",
       " 'here',\n",
       " 'cripple',\n",
       " 'jane',\n",
       " \"fountain's\",\n",
       " 'side',\n",
       " 'goad',\n",
       " 'distress',\n",
       " 'forelaid',\n",
       " 'take',\n",
       " 'strive',\n",
       " 'blight',\n",
       " 'nearest',\n",
       " 'pillar',\n",
       " 'rest',\n",
       " 'cloud',\n",
       " 'throb',\n",
       " 'slave',\n",
       " 'ask',\n",
       " \"time's\",\n",
       " 'delusive',\n",
       " 'tide',\n",
       " 'spake',\n",
       " 'regin',\n",
       " 'adown',\n",
       " 'envy',\n",
       " 'calumny',\n",
       " 'solemn',\n",
       " 'teach',\n",
       " 'know',\n",
       " 'than',\n",
       " 'more',\n",
       " 'break',\n",
       " 'discontent',\n",
       " 'get',\n",
       " 'ill',\n",
       " 'name',\n",
       " 'augur',\n",
       " 'because',\n",
       " 'bore',\n",
       " '—',\n",
       " 'thro',\n",
       " 'breast',\n",
       " 'fatal',\n",
       " 'sword',\n",
       " 'send',\n",
       " 'live',\n",
       " 'soft',\n",
       " 'rage',\n",
       " 'stormy',\n",
       " 'ignorant',\n",
       " 'didst',\n",
       " 'smother',\n",
       " 'mankind',\n",
       " 'time',\n",
       " 'dip',\n",
       " 'arrow',\n",
       " 'savage',\n",
       " 'moon',\n",
       " 'star',\n",
       " 'anxious',\n",
       " 'twilight',\n",
       " 'thing',\n",
       " 'phantasmal',\n",
       " 'great']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff2016e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09424458"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity('he', 'his')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c98eb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_vector_averaging(sentence, model):\n",
    "    embeddings = [model.wv[word] for word in sentence if word in vocab]\n",
    "    \n",
    "    if len(embeddings) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    else:\n",
    "        return np.mean(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "258efc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    features.append(sentence_to_vector_averaging(sentence, w2v_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0f1a7859",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [f'x{i}' for i in range(w2v_model.vector_size)]\n",
    "\n",
    "df_text = pd.DataFrame(features, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76eb6064",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x91</th>\n",
       "      <th>x92</th>\n",
       "      <th>x93</th>\n",
       "      <th>x94</th>\n",
       "      <th>x95</th>\n",
       "      <th>x96</th>\n",
       "      <th>x97</th>\n",
       "      <th>x98</th>\n",
       "      <th>x99</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.002635</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>-0.001092</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>-0.004121</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>-0.001603</td>\n",
       "      <td>-0.004441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>-0.000502</td>\n",
       "      <td>0.004003</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001567</td>\n",
       "      <td>0.001821</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>-0.002611</td>\n",
       "      <td>-0.001741</td>\n",
       "      <td>0.004161</td>\n",
       "      <td>-0.001008</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002191</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>-0.002866</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>-0.000595</td>\n",
       "      <td>0.002542</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.003221</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.004012</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>-0.003450</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>-0.005104</td>\n",
       "      <td>-0.005206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003314</td>\n",
       "      <td>-0.001148</td>\n",
       "      <td>-0.001469</td>\n",
       "      <td>0.002458</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>-0.001765</td>\n",
       "      <td>0.001462</td>\n",
       "      <td>-0.001077</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001055</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.003790</td>\n",
       "      <td>-0.002903</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>-0.002660</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.002954</td>\n",
       "      <td>-0.004730</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002590</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.003518</td>\n",
       "      <td>-0.002318</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>-0.001475</td>\n",
       "      <td>-0.002432</td>\n",
       "      <td>-0.002021</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002718</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.003443</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.002879</td>\n",
       "      <td>0.008274</td>\n",
       "      <td>0.001731</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>-0.000856</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>-0.003517</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>-0.000828</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.002940</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>-0.000404</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.002123</td>\n",
       "      <td>-0.000700</td>\n",
       "      <td>-0.000375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001745</td>\n",
       "      <td>-0.001104</td>\n",
       "      <td>-0.001014</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>-0.005261</td>\n",
       "      <td>-0.000980</td>\n",
       "      <td>0.004666</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.000383</td>\n",
       "      <td>-0.000077</td>\n",
       "      <td>-0.002621</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>-0.005285</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>-0.003106</td>\n",
       "      <td>-0.005056</td>\n",
       "      <td>-0.005158</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000337</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>-0.000342</td>\n",
       "      <td>-0.002319</td>\n",
       "      <td>-0.001741</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>-0.004805</td>\n",
       "      <td>0.001432</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.002676</td>\n",
       "      <td>-0.000389</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>-0.001215</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>-0.000846</td>\n",
       "      <td>-0.004233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>-0.005863</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>0.004185</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>-0.003276</td>\n",
       "      <td>-0.003367</td>\n",
       "      <td>-0.002619</td>\n",
       "      <td>-0.001965</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>-0.005223</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>-0.001118</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>-0.001881</td>\n",
       "      <td>-0.001437</td>\n",
       "      <td>-0.002837</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.002687</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001411</td>\n",
       "      <td>-0.000660</td>\n",
       "      <td>-0.002264</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>-0.002617</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>-0.001918</td>\n",
       "      <td>-0.001979</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>-0.000824</td>\n",
       "      <td>-0.001819</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>-0.001619</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>-0.001822</td>\n",
       "      <td>-0.000323</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>-0.000833</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003417</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.003794</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>-0.000142</td>\n",
       "      <td>-0.002204</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x0        x1        x2        x3        x4        x5        x6  \\\n",
       "0   -0.002635  0.002073  0.001640 -0.001092  0.000702 -0.004121  0.003429   \n",
       "1   -0.001567  0.001821  0.000933  0.000537  0.001855 -0.002611 -0.001741   \n",
       "2   -0.003221  0.001805  0.004012  0.000697  0.002601 -0.003450  0.001961   \n",
       "3    0.001055  0.000047  0.003790 -0.002903  0.002489 -0.002660  0.001892   \n",
       "4    0.002718  0.000757  0.003443  0.002107 -0.000521  0.000391  0.002879   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "150 -0.000828  0.001477  0.002940  0.000595  0.001523 -0.000404  0.000284   \n",
       "151  0.000383 -0.000077 -0.002621  0.000914 -0.005285  0.002970  0.001621   \n",
       "152  0.002676 -0.000389  0.002747  0.002768 -0.001215  0.000844  0.000177   \n",
       "153 -0.005223  0.001633 -0.001118  0.001054 -0.001881 -0.001437 -0.002837   \n",
       "154 -0.000824 -0.001819  0.000277 -0.001619  0.000288 -0.001822 -0.000323   \n",
       "\n",
       "           x7        x8        x9  ...       x91       x92       x93  \\\n",
       "0    0.003238 -0.001603 -0.004441  ...  0.001299  0.003675 -0.000237   \n",
       "1    0.004161 -0.001008  0.001186  ... -0.002191  0.002025 -0.002866   \n",
       "2    0.002532 -0.005104 -0.005206  ...  0.003314 -0.001148 -0.001469   \n",
       "3    0.002954 -0.004730 -0.000013  ...  0.002590  0.000015 -0.003518   \n",
       "4    0.008274  0.001731 -0.000097  ...  0.000062 -0.000856  0.000222   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "150  0.002123 -0.000700 -0.000375  ... -0.001745 -0.001104 -0.001014   \n",
       "151 -0.003106 -0.005056 -0.005158  ... -0.000337  0.002719 -0.000342   \n",
       "152  0.002195 -0.000846 -0.004233  ...  0.000097 -0.005863 -0.000197   \n",
       "153  0.000140  0.002687  0.000493  ... -0.001411 -0.000660 -0.002264   \n",
       "154  0.002320 -0.000833  0.000247  ...  0.003417  0.000204  0.003794   \n",
       "\n",
       "          x94       x95       x96       x97       x98       x99    y  \n",
       "0    0.001576 -0.000502  0.004003  0.000927  0.000313  0.002844 -1.0  \n",
       "1    0.001479 -0.000595  0.002542  0.000635  0.001484  0.001236 -1.0  \n",
       "2    0.002458  0.001178  0.001007 -0.001765  0.001462 -0.001077 -1.0  \n",
       "3   -0.002318  0.004180 -0.001475 -0.002432 -0.002021  0.003180 -1.0  \n",
       "4    0.001366  0.001535 -0.003517  0.000665 -0.000013  0.000907 -1.0  \n",
       "..        ...       ...       ...       ...       ...       ...  ...  \n",
       "150  0.001452  0.001703  0.001786 -0.005261 -0.000980  0.004666 -1.0  \n",
       "151 -0.002319 -0.001741  0.001024 -0.004805  0.001432  0.001137 -1.0  \n",
       "152  0.004185  0.002983 -0.003276 -0.003367 -0.002619 -0.001965 -1.0  \n",
       "153  0.000308  0.004514 -0.002617  0.000905 -0.001918 -0.001979 -1.0  \n",
       "154  0.001993  0.001058 -0.000142 -0.002204  0.000608  0.002202 -1.0  \n",
       "\n",
       "[155 rows x 101 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text['y'] = [float(x) for x in negative['Sentiment']]\n",
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ffacbab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature vectors as csv\n",
    "df_text.to_csv('negative.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29ecc06",
   "metadata": {},
   "source": [
    "### Create Feature Vectors from Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7b3088f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = 100\n",
    "w2v_model = Word2Vec(text, vector_size=vector_size, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3fcffb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 342\n"
     ]
    }
   ],
   "source": [
    "vocab = w2v_model.wv.index_to_key\n",
    "vocab_length = len(vocab)\n",
    "\n",
    "print(f'Vocabulary Size: {format(vocab_length)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e7a4d247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['future',\n",
       " 'stifle',\n",
       " 'on',\n",
       " 'may',\n",
       " 'barn',\n",
       " 'nerve',\n",
       " 'than',\n",
       " 'pathetic',\n",
       " 'blast',\n",
       " 'inand',\n",
       " 'fetter',\n",
       " 'bear',\n",
       " 'life',\n",
       " 'know',\n",
       " 'shrill',\n",
       " 'lave',\n",
       " 'live',\n",
       " 'moloch',\n",
       " 'pursue',\n",
       " 'then',\n",
       " 'end',\n",
       " 'echo',\n",
       " \"'twas\",\n",
       " 'within',\n",
       " 'cross',\n",
       " 'teach',\n",
       " 'open',\n",
       " 'satrap',\n",
       " 'dread',\n",
       " 'darkness',\n",
       " 'watch',\n",
       " 'nice',\n",
       " 'ah',\n",
       " 'guard',\n",
       " 'gaud',\n",
       " 'guile',\n",
       " 'star',\n",
       " 'eye',\n",
       " 'some',\n",
       " 'beat',\n",
       " 'mood',\n",
       " 'thus',\n",
       " 'morn',\n",
       " 'slavery',\n",
       " 'etch',\n",
       " 'mile',\n",
       " 'howl',\n",
       " 'prison',\n",
       " 'groom',\n",
       " 'him',\n",
       " 'ripe',\n",
       " 'pain',\n",
       " 'most',\n",
       " 'augur',\n",
       " 'sorrowful',\n",
       " 'make',\n",
       " 'face',\n",
       " \"an'\",\n",
       " 'weird',\n",
       " 'whole',\n",
       " 'pity',\n",
       " 'nothing',\n",
       " 'inclose',\n",
       " 'she',\n",
       " 'more',\n",
       " 'behold',\n",
       " 'angel',\n",
       " 'blindness',\n",
       " 'silk',\n",
       " 'fraud',\n",
       " 'ridiculous',\n",
       " 'featureless',\n",
       " 'death',\n",
       " 'scatter',\n",
       " 'load',\n",
       " 'ruin',\n",
       " 'steal',\n",
       " 'wilt',\n",
       " 'monster',\n",
       " 'generation',\n",
       " 'quicken',\n",
       " 'human',\n",
       " 'melt',\n",
       " 'utter',\n",
       " 'down',\n",
       " 'shepherd',\n",
       " 'sword',\n",
       " 'despair',\n",
       " 'law',\n",
       " 'get',\n",
       " 'word',\n",
       " 'dark',\n",
       " 'flight',\n",
       " 'throb',\n",
       " 'sleep',\n",
       " 'our',\n",
       " 'one',\n",
       " 'wild',\n",
       " 'house',\n",
       " 'thousand',\n",
       " 'moment',\n",
       " 'accomplish',\n",
       " 'thine',\n",
       " 'priest',\n",
       " 'stock',\n",
       " 'foggy',\n",
       " 'selfishness',\n",
       " 'hang',\n",
       " 'solemn',\n",
       " 'her',\n",
       " 'but',\n",
       " 'maidenhead',\n",
       " 'ago',\n",
       " 'slay',\n",
       " 'torment',\n",
       " 'dawn',\n",
       " 'break',\n",
       " 'lose',\n",
       " 'receave',\n",
       " 'forelaid',\n",
       " 'god',\n",
       " 'bad',\n",
       " 'no',\n",
       " 'o',\n",
       " 'rude',\n",
       " 'sweep',\n",
       " 'runt',\n",
       " 'fight',\n",
       " 'land',\n",
       " 'hi',\n",
       " 'strive',\n",
       " 'lap',\n",
       " 'monkey',\n",
       " 'breast',\n",
       " 'must',\n",
       " 'away',\n",
       " 'nail',\n",
       " 'enough',\n",
       " 'trouble',\n",
       " 'always',\n",
       " 'blankness',\n",
       " 'hate',\n",
       " 'tight',\n",
       " \"god's\",\n",
       " 'sharp',\n",
       " 'regin',\n",
       " 'because',\n",
       " 'could',\n",
       " 'gloom',\n",
       " 'might',\n",
       " 'stiff',\n",
       " 'two',\n",
       " 'offspring',\n",
       " 'into',\n",
       " 'scare',\n",
       " 'name',\n",
       " 'around',\n",
       " 'false',\n",
       " 'mourn',\n",
       " 'for',\n",
       " 'dare',\n",
       " 'distress',\n",
       " 'sitteth',\n",
       " 'if',\n",
       " 'delusive',\n",
       " 'fury',\n",
       " 'home',\n",
       " 'they',\n",
       " 'vapour',\n",
       " 'fer',\n",
       " 'clatter',\n",
       " 'rough',\n",
       " 'or',\n",
       " 'gray',\n",
       " 'how',\n",
       " 'i',\n",
       " 'shadow',\n",
       " 'child',\n",
       " \"captive's\",\n",
       " 'thy',\n",
       " 'thing',\n",
       " 'give',\n",
       " 'moan',\n",
       " 'run',\n",
       " 'tinkle',\n",
       " 'fountain',\n",
       " 'a',\n",
       " 'rage',\n",
       " 'lone',\n",
       " 'tire',\n",
       " 'roll',\n",
       " 'wreck',\n",
       " 'say',\n",
       " 'be',\n",
       " 'meditate',\n",
       " 'calumny',\n",
       " 'moon',\n",
       " 'cloudy',\n",
       " 'obliterate',\n",
       " 'see',\n",
       " 'pang',\n",
       " 'dwell',\n",
       " 'an',\n",
       " 'world',\n",
       " 'thro',\n",
       " 'hope',\n",
       " 'fool',\n",
       " 'tempest',\n",
       " 'slumber',\n",
       " 'hell',\n",
       " 'pillar',\n",
       " 'melancholy',\n",
       " 'scorn',\n",
       " 'way',\n",
       " 'lord',\n",
       " 'look',\n",
       " 'head',\n",
       " 'liveliest',\n",
       " 'madness',\n",
       " 'mole',\n",
       " 'poor',\n",
       " 'curse',\n",
       " 'weight',\n",
       " 'spoil',\n",
       " 'up',\n",
       " 'blend',\n",
       " 'hand',\n",
       " 'from',\n",
       " 'lonesome',\n",
       " 'them',\n",
       " 'smile',\n",
       " 'fill',\n",
       " 'let',\n",
       " 'pu',\n",
       " 'of',\n",
       " 'goad',\n",
       " 'take',\n",
       " 'trail',\n",
       " 'shore',\n",
       " 'old',\n",
       " \"i've\",\n",
       " 'not',\n",
       " 'wander',\n",
       " 'at',\n",
       " 'gallic',\n",
       " 'bat',\n",
       " 'fiery',\n",
       " 'dip',\n",
       " 'cruell',\n",
       " 'humanness',\n",
       " 'foe',\n",
       " 'cloud',\n",
       " 'till',\n",
       " 'bleed',\n",
       " 'mine',\n",
       " 'warn',\n",
       " 'cold',\n",
       " 'torture',\n",
       " 'fray',\n",
       " 'while',\n",
       " 'visual',\n",
       " \"death's\",\n",
       " 'forcd',\n",
       " 'off',\n",
       " 'lay',\n",
       " 'bind',\n",
       " 'save',\n",
       " 'heap',\n",
       " 'gun',\n",
       " 'wa',\n",
       " 'faint',\n",
       " 'twas',\n",
       " 'threaten',\n",
       " 'hearthstone',\n",
       " 'wrack',\n",
       " 'folly',\n",
       " 'lucrece',\n",
       " 'thee',\n",
       " 'dumb',\n",
       " 'perish',\n",
       " 'crush',\n",
       " 'disunion',\n",
       " 'unloved',\n",
       " 'forlorn',\n",
       " 'burn',\n",
       " 'monstrous',\n",
       " 'sophist',\n",
       " 'bow',\n",
       " 'co',\n",
       " 'droop',\n",
       " 'beam',\n",
       " 'what',\n",
       " 'lie',\n",
       " 'glance',\n",
       " 'vain',\n",
       " 'once',\n",
       " 'this',\n",
       " 'great',\n",
       " 'haunt',\n",
       " 'waver',\n",
       " 'sad',\n",
       " 'glen',\n",
       " 'afar',\n",
       " 'lift',\n",
       " \"ne'er\",\n",
       " 'wrong',\n",
       " \"e'en\",\n",
       " 'weak',\n",
       " 'war',\n",
       " 'wither',\n",
       " 'friend',\n",
       " 'corps',\n",
       " 'sorrow',\n",
       " 'rave',\n",
       " 'would',\n",
       " 'multiply',\n",
       " 'still',\n",
       " 'slave',\n",
       " 'answer',\n",
       " 'vehement',\n",
       " 'cough',\n",
       " 'spake',\n",
       " 'heavy',\n",
       " 'blind',\n",
       " 'here',\n",
       " 'deaf',\n",
       " 'wind',\n",
       " 'struggle',\n",
       " 'discontent',\n",
       " 'each',\n",
       " 'enemy',\n",
       " 'infernal',\n",
       " 'such',\n",
       " 'earth',\n",
       " 'line',\n",
       " 'none',\n",
       " 'silly',\n",
       " 'these',\n",
       " 'fall',\n",
       " 'lowly',\n",
       " 'woman',\n",
       " 'and']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4a6b1d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = [w2v_model.wv[word] for word in vocab]\n",
    "len(vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e1304879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_vector_averaging(sentence, model):\n",
    "    embeddings = [model.wv[word] for word in sentence if word in vocab]\n",
    "    \n",
    "    if len(embeddings) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    else:\n",
    "        return np.mean(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a3a160fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "\n",
    "for sentence in text:\n",
    "    features.append(sentence_to_vector_averaging(sentence, w2v_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a7b18a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [f'x{i}' for i in range(w2v_model.vector_size)]\n",
    "\n",
    "df_text = pd.DataFrame(features, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8bcafa9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x91</th>\n",
       "      <th>x92</th>\n",
       "      <th>x93</th>\n",
       "      <th>x94</th>\n",
       "      <th>x95</th>\n",
       "      <th>x96</th>\n",
       "      <th>x97</th>\n",
       "      <th>x98</th>\n",
       "      <th>x99</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000616</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>-0.000671</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>-0.001334</td>\n",
       "      <td>-0.000871</td>\n",
       "      <td>-0.000537</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>-0.000420</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>-0.001009</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>-0.000478</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>-0.000249</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>-0.000393</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>-0.000452</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>-0.001722</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000641</td>\n",
       "      <td>-0.000373</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>-0.001206</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>-0.000160</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>-0.000247</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>-0.000888</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000291</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>-0.000140</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>-0.000688</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>-0.000351</td>\n",
       "      <td>-0.000749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>-0.000553</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>-0.000901</td>\n",
       "      <td>-0.000380</td>\n",
       "      <td>-0.000593</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>-0.000494</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>-0.000577</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>-0.000773</td>\n",
       "      <td>-0.001599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>-0.000304</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>-0.000190</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1        x2        x3        x4        x5        x6  \\\n",
       "0 -0.000616 -0.000162 -0.000671  0.000768 -0.001334 -0.000871 -0.000537   \n",
       "1  0.000027  0.000058  0.000543  0.000483  0.000802 -0.000478  0.001076   \n",
       "2 -0.000106 -0.000641 -0.000373  0.000291  0.000176 -0.001206  0.000184   \n",
       "3 -0.000291  0.000453  0.000718 -0.000140  0.000211 -0.000688  0.000363   \n",
       "4  0.000468  0.001932  0.000160 -0.000494  0.000595 -0.000577  0.000644   \n",
       "\n",
       "         x7        x8        x9  ...       x91       x92       x93       x94  \\\n",
       "0  0.000711 -0.000420  0.000655  ...  0.000768 -0.000075  0.000193  0.000314   \n",
       "1  0.000831 -0.000249 -0.000019  ...  0.001031 -0.000393  0.000519  0.001661   \n",
       "2  0.000133  0.000293  0.000619  ... -0.000236  0.000295  0.000194 -0.000160   \n",
       "3  0.001737 -0.000351 -0.000749  ...  0.000426 -0.000056 -0.000553  0.000964   \n",
       "4  0.001340 -0.000773 -0.001599  ...  0.000071 -0.000304 -0.000064  0.000290   \n",
       "\n",
       "        x95       x96       x97       x98       x99  y  \n",
       "0  0.000973  0.000138 -0.000011  0.000423 -0.001009 -1  \n",
       "1 -0.000452  0.000307 -0.001722  0.000478  0.000359 -1  \n",
       "2  0.000867  0.000472 -0.000247  0.000738 -0.000888 -1  \n",
       "3  0.000263 -0.000901 -0.000380 -0.000593  0.000548 -1  \n",
       "4  0.000762  0.001195 -0.000190  0.000831  0.000315 -1  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text['y'] = [-1] * len(df_text)\n",
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cfa7016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature vectors as csv\n",
    "df_text.to_csv('negative_generated.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
